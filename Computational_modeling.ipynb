{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "   # Maxwell's demon with bar magnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from numba import jit,njit, prange\n",
    "\n",
    "%matplotlib widget  \n",
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up constants\n",
    "$B_0$ the strenght of magnetic field.\n",
    "At this stage, we have to tweek the adjustable constants to achieve the desired motion of the magnets. What I noticed was the resistive force being too high in comparison to fluctuating force. Almost comparable sizes, there might be a few ways to fix this.\n",
    "### Fixed constants\n",
    "#### Moment of inertia of a cylinder\n",
    "http://schoolpress-blogs.myschoolcdn.com/blogs.norfolkacademy.org/sites/11/2018/10/Screen-Shot-2018-10-10-at-10.36.29-PM.png this websites contains the formula, no proof given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general constants\n",
    "d = 10**(-7)       # distance between the two magnets, right now with this separation the magnets would be touching, will change this later\n",
    "u_0 = 4*np.pi*10**(-7) # vacuum permeability\n",
    "T = 273.15 + 20    # temperature of the heath bath\n",
    "B_0 = 0.02         # magnitude of external magnetic field, 1000 Gauss chosen as the highest B field for Fe, at 200 gauss now\n",
    "k_b = 1.380649*10**(-23)  # Boltzmans constant\n",
    "nu = 10**(-4)      # 10**(-3)viscosity of water at T=20C, so the medium is 10 times less viscos than water \n",
    "E_unit = k_b*T     # kT unit of energy\n",
    "\n",
    "# system bar magnet\n",
    "ro_s = 7860          # density of iron\n",
    "l_s = 5*10**(-7)     # length of the cylinder\n",
    "R_s = 5*10**(-8)     # radius \n",
    "V = np.pi*(R_s**2)*l_s # Volume\n",
    "M_s = ro_s*V         # mass\n",
    "I_s = (M_s*R_s**2)/4 + (M_s*l_s**2)/12   # moment of inertia\n",
    "Mag_s = 0.8*10**(6)  # Magnetization A/m\n",
    "mu_s = Mag_s*V       # magnetic moment\n",
    "gam_s = 6*np.pi*nu*(l_s**2)*R_s         # coefficient of friction\n",
    "b_s = np.sqrt(2*gam_s*k_b*T)    # coefficient b, strenght fluctuating force \n",
    "\n",
    "# demon paramagnet\n",
    "x_d = 7.2*10**(-3) # fe3O4 susceptibility\n",
    "ro_d = 5000        # density of Fe3O4   \n",
    "M_d = ro_d*V       # mass\n",
    "R_d = ( (2/3*V**2) / (np.pi**2) ) **(1/6)         # radius\n",
    "l_d = V/np.pi * ((2/3*V**2) / (np.pi**2))**(-1/3) # height\n",
    "I_d = (M_d*R_d**2)/4 + (M_d*l_d**2)/12    # moment of inertia\n",
    "gam_d = 6*np.pi*nu*(l_d**2)*R_d           # coefficient of friction \n",
    "b_d = np.sqrt(2*gam_d*k_b*T)              # coefficient b\n",
    "Mag_d = 10**4                             # magnetization \n",
    "mu_d_max = Mag_d*V                        # maximum magnetic moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjustable constants\n",
    "with physical limitations\n",
    "\n",
    "### Magnetization of system magnet $M_s$\n",
    "The saturation value of Magnetization for magnets made out of close to pure iron speciments was found to be $1.7x10^6A/m$ which should reach for a magnetic field of about 1000 Gauss(2) (Earths magnetic field ranges from 0.25-0.6 Gauss at the surface). The peak magnetic field of 1000 Gauss doesn't limit us from using more intense fields. Sources: \n",
    "1. https://scihubtw.tw/10.1063/1.2163571, https://aip.scitation.org/doi/10.1063/1.2163571 - summary of multiple experimental results from different groups/people\n",
    "2. https://www.jstor.org/stable/pdf/20025449.pdf - Paper does not include units\n",
    "3. http://www.brainkart.com/article/Solved-Problems--Magnetic-and-Superconducting-Materials_6825/ - as part of one exercise\n",
    "\n",
    "Useful website providing conversions between regularly used units in magnetism: https://www.ieeemagnetics.org/index.php?option=com_content&view=article&id=118&Itemid=107\n",
    "\n",
    "The Currie temperature of Iron is about 1000K so that puts an upper bound on what the temperature of the heath bath could be but we will work with room temperatures anyway. \n",
    "\n",
    "Just to start of I'll choose the Magnetization of the system to be half the saturation value, that is probably way too high.\n",
    "\n",
    "### Magnetization of demon magnet $M_d$\n",
    "At first I wanted to make the magnet out Fe3o4 material which has a very high susceptibility 7.2x10^-3. This value was taken from EM notes and later I found a same value on http://hyperphysics.phy-astr.gsu.edu/hbase/Tables/magprop.html website that containes susceptibilities of other materials with references. This susceptibility should be valid for room temperatures. \n",
    "\n",
    "However in a research paper http://www.ijsei.com/papers/ijsei-10312-13.pdf that shows the relation between magnetization and applied magnetic field H the magnetization M calculated from that graph was very different to the one obtained from susceptibility relation. Not sure what is going on, I might have misread the graph caption and it could display the relation for a different material or at different temperature, or there is an error in some of the calculations or a conceptual flaw in the way I am approaching this. What is even more bizare is that from different papers yielded different magnetization relations. Let's leave this for now and work with a theoretical parameter that fits within a reasonable realistic range of values but can be freely adjusted to our desire. Thus it will not necessarly represent a material or a mixter of compounds that can be found in nature. \n",
    "\n",
    "Listing all the relevant papers and website so I can get back to this later.\n",
    "1. http://www.ijsei.com/papers/ijsei-10312-13.pdf - first paper used to calculate M\n",
    "2. https://www.researchgate.net/publication/224131637_Magnetic_properties_of_Fe3O4_nanoparticles_coated_with_oleic_and_dodecanoic_acids - another paper with graphs of M/H\n",
    "3. https://www.sigmaaldrich.com/catalog/product/SAJ/151380?lang=en&region=CZ - website that sells fe3o4 and gives its density\n",
    "4. https://chem.libretexts.org/Courses/Saint_Marys_College_Notre_Dame_IN/CHEM_431%3A_Inorganic_Chemistry_%28Haas%29/CHEM_431_Readings/14%3A_Magnetism/14.02%3A_Magnetic_Properties_of_Materials - Curie's law, susceptibility dependent on T\n",
    "5. https://link.springer.com/article/10.1007/s00269-011-0472-x - Currie Temperature of Fe3o4 770-870K\n",
    "6. https://www.ecosia.org/images?q=magnetization%20curves%20of%20fe3o4%20low%20field#id=9E7345B11C16B6D6A9E06087286E8683FAB1CDA7 - another hysteriosis curves\n",
    "7. file:///C:/Users/schwarz/Desktop/Magnetic_Vortex_and_Hyperthermia_Suppression_in_Mu.pdf - the one I used in another M calculation\n",
    "8. http://ferrocell.us/references/Magnetite%20%28Fe3O4%29_%20Properties%20Synthesis%20and%20Applications.pdf - Document about Fe3o4, its physical properties etc.. contains a lot of info\n",
    "\n",
    "\n",
    "### Drag coefficient $\\gamma$\n",
    "As of now I have not been able to find a precise expresion for what the drag coefficient on a rotating cylinder should. I have spend quite a considerable time on this but now I really need to move forward and make some progress. If needed I can come back to finding the appropriate coefficient later, for now the group's coefficient will be used, I have contacted them asking about its origin but they did not get to me yet. \n",
    "The drag coefficient that they used was\n",
    "$$\\beta=6\\pi\\mu L^3$$\n",
    "\n",
    "This expression if valid is applicable for needles so I might change one of the L which is a length of the needle into a radius of the cylinder. \n",
    "\n",
    "Notes on drag coefficient research\n",
    "The drag force that we are looking for should be proportional to first order in velocity of the object. This should be reasonable as for small objects the reynold number is small, less than 1 and in this limit the stoke's law is a good description. Stoke's law only applies to spherical objects. \n",
    "Useful links:\n",
    "\n",
    "1.https://www.quora.com/Is-Stokes-law-F-6%CF%80r%C2%A3v-applicable-for-cylinder-shapes-or-any-other-shape - states the general drag force for any object\n",
    "2.https://phys.libretexts.org/Bookshelves/Classical_Mechanics/Book%3A_Classical_Mechanics_%28Dourmashkin%29/08%3A_Applications_of_Newtons_Second_Law/8.06%3A_Drag_Forces_in_Fluids - stokes law, drag forces and viscosity coefficients\n",
    "3.https://scihubtw.tw/10.1016/0375-9601(79)90040-9 - paper about force on a rotating cylinder with holes\n",
    "4.https://mae.ufl.edu/~uhk/STOKES-DRAG-FORMULA.pdf - derivation of stokes law\n",
    "5.https://phys.libretexts.org/Bookshelves/Classical_Mechanics/Supplemental_Modules_%28Classical_Mechanics%29/Fluids/1.7%3A_Stokes%E2%80%99_Law - stokes law dimensional analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing time steps \n",
    "I might want to investigate a bit more on what the appropriate timesteps should be, Ian in his notes says that the time steop dt is required to be larger than the time at which the random changes happen but that the later goes to zero so there is almost no limit on the dt which can be made small. Let's start of with dt in microseconds. Found an article online that showed that on average molecules of N2 at room temperature and pressure colide with frequency of $10^9Hz$. https://www.tec-science.com/thermodynamics/kinetic-theory-of-gases/mean-free-path-collision-frequency/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_steps(tf, N):\n",
    "    '''   \n",
    "    Creates an array of N+1 evenly spaced t values from 0 to tf, this corresponds to N time steps,\n",
    "    the second stop argument is not included so in order to include the tf one step tf/N was added.\n",
    "    \n",
    "    Parameters\n",
    "    tf: final time, time period of solving the equation\n",
    "    N:  number of time steps\n",
    "    Rerturns\n",
    "    -----\n",
    "    N+1 values of t values between (0,tf) time interval\n",
    "    '''\n",
    "    return np.arange(0, tf + tf/N, tf/N)\n",
    "\n",
    "t_f = 1e-4  # final time\n",
    "N = int(1e5)\n",
    "h = t_f/N\n",
    "t_points = t_steps(t_f, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining useful constants\n",
    "which will speed up the caluclations when evaluating the differential equations. Just collecting all the constants so that they dont have to be calculated over and over again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system magnet\n",
    "S1 = u_0*mu_s/(4*np.pi*d**(3)*I_s)\n",
    "S2 = B_0*mu_s/I_s\n",
    "S3 = gam_s/I_s\n",
    "S4 = b_s/I_s\n",
    "# demon magnet\n",
    "D1 = u_0*mu_s/(4*np.pi*d**(3)*I_d)\n",
    "D2 = gam_d/I_d\n",
    "D3 = b_d/I_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is correct that the fluctuating force is bigger on system but it makes the demon move faster because the moment of inertia overweights the strength b of noise term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of the strength of the fluctuating forces\n",
      " 2.8574404296988045\n"
     ]
    }
   ],
   "source": [
    "print(\"ratio of the strength of the fluctuating forces\\n\", b_s/b_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = mu_d_max*5/t_f   # rate at which the magnetization is increasing\n",
    "\n",
    "def mu_d(t):\n",
    "    \"\"\"calculates the magnetic moment of the demon paramagnet\"\"\"\n",
    "    if (t <= t_f/5):\n",
    "        return alpha*t\n",
    "    else:\n",
    "        return mu_d_max # m = Md*V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def langevin(r,t_points):\n",
    "    ''' Calculates the right hand sight of the diff eqs\n",
    "    r is a vector containing: r = [[theta_s, w_s],\n",
    "                                  [theta_d, w_d]]\n",
    "    '''\n",
    "    # initializing empty arrays that will store the resulting trajectories\n",
    "    theta_s = np.empty(t_points.shape, dtype = 'float64')\n",
    "    theta_d = np.empty(t_points.shape, dtype = 'float64')\n",
    "    w_s = np.empty(t_points.shape, dtype = 'float64')\n",
    "    w_d = np.empty(t_points.shape, dtype = 'float64')\n",
    "    \n",
    "    # time step\n",
    "    h = t_points[-1]/len(t_points)\n",
    "    \n",
    "    # storing the initial values\n",
    "    theta_s[0] = r[0,0]\n",
    "    theta_d[0] = r[1,0]\n",
    "    w_s[0] = r[0,1]\n",
    "    w_d[0] = r[1,1]\n",
    "    \n",
    "    # solving the dif-eq\n",
    "    for idx in range(1,len(t_points)):\n",
    "        t = t_points[idx] # current time\n",
    "        # abreviation for variables at t\n",
    "        th_s_t =  theta_s[idx-1]\n",
    "        th_d_t = theta_d[idx-1]\n",
    "        w_s_t = w_s[idx-1]\n",
    "        w_d_t = w_d[idx-1]\n",
    "        # calculate the variables at t+dt\n",
    "        theta_s[idx] = th_s_t + h*w_s_t\n",
    "        theta_d[idx] = th_d_t + h*w_d_t\n",
    "        w_s[idx] = (w_s_t + h*S1*mu_d(t)*(np.sin(th_s_t)*np.cos(th_d_t) + 2*np.sin(th_d_t)*np.cos(th_s_t)) -\n",
    "                            h*S2*np.sin(th_s_t) -\n",
    "                            h*S3*w_s_t +\n",
    "                            h**(1/2)*S4*np.random.normal()  \n",
    "                    )\n",
    "        w_d[idx] = (w_d_t + h*D1*mu_d(t)*(np.sin(th_d_t)*np.cos(th_s_t) + 2*np.sin(th_s_t)*np.cos(th_d_t)) -\n",
    "                            h*D2*w_d_t  +\n",
    "                            h**(1/2)*D3*np.random.normal()  \n",
    "                   )\n",
    "\n",
    "    return np.array([[theta_s, w_s],[theta_d, w_d]], dtype = 'float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial conditions, setting initial values for magnet's angles and velocities\n",
    "init = np.array([[0,0],[np.pi,0]], dtype = 'float64')\n",
    "solution = langevin(init,t_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1d7fb25a4641df92e91137a9100137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_angles(sol,t_points):\n",
    "    '''Plots the angle trajectories'''\n",
    "    plt.figure(figsize=(10.5, 4.2))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(t_points,sol[0,0])\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"t (s)\")\n",
    "    plt.ylabel(\"$\\\\theta_s$\"+\" (rad)\")\n",
    "    plt.title(\"System magnet\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(t_points,sol[1,0])\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"t (s)\")\n",
    "    plt.ylabel(\"$\\\\theta_d$\"+\" (rad)\")\n",
    "    plt.title('Demon magnet')\n",
    "    \n",
    "plot_angles(solution,t_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting a 3D graph of the system-demon interaction potential $U_{int}$ \n",
    "This might be usefull so I see where the minimas are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b69392a405463d97eed53751692eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ths = np.outer(np.linspace(-np.pi, np.pi, 50), np.ones(50))\n",
    "thd = ths.copy().T # transpose\n",
    "\n",
    "U_int_plot =  mu_d_max*u_0*mu_s/(4*np.pi*d**(3)) * (np.cos(ths)*np.cos(thd) - 2*np.sin(ths)*np.sin(thd) )\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.plot_surface(ths, thd, U_int_plot/E_unit,cmap='viridis', edgecolor='none')\n",
    "ax.set_title('$U_{int}(\\\\theta_s,\\\\theta_d)$')\n",
    "ax.set_xlabel(\"$\\\\theta_s$\")\n",
    "ax.set_ylabel(\"$\\\\theta_d$\")\n",
    "ax.set_zlabel(\"U (kT)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are two minima if we let both angles to vary. I really should have analyzed the potential function earlier to get a better idea of where do the magnets tend to go. The two minima are when both the mangets lie flat parallel and their magnetic moments point in the same direction. This changes my entire perception of the dynamics between the system and the demon. So they are not trying to antialign all the time because that is not the only point where the derivative of U is zero. The entire time I thought that the magnets will try to stay antialigned to each other because that was their global minimum supposedly, but it is not. This might make the exploitation period slightly more complicated because no we cannot just say that system is pointing the opposite direction with respect to the demon. Also not to forget this potential is still missing one term the $B_0$ interaction with system magnet. Let's plot that and see what we get. Now the multiplicative constants can't be neglected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D graph of the complete U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af78bbbd0574ffa974aff9a2ed6175b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "U_full = mu_d_max*u_0*mu_s/(4*np.pi*d**(3))*(np.cos(ths)*np.cos(thd) - 2*np.sin(ths)*np.sin(thd)) - B_0*mu_s*np.cos(ths)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.plot_surface(ths, thd, U_full/E_unit,cmap='viridis', edgecolor='none')\n",
    "ax.set_title('$U_{total}(\\\\theta_s,\\\\theta_d)$')\n",
    "ax.set_xlabel(\"$\\\\theta_s$\")\n",
    "ax.set_ylabel(\"$\\\\theta_d$\")\n",
    "ax.set_zlabel(\"U (kT)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so I ranged the B0 from around 0.001 to 0.03 to see how it affects the potential energy. When the B0 was around the 0.001 the interaction only potential function was close to being unchanged at all. The minima remained roughly at the same angles. When the B0 was cranked up al the way to 0.03 the minima were slowly pushed to the $\\theta_s=0$ angle but the potential was getting deeper and steeper, harder for the particles to move away from their minimas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of B0 for which the potential U turns into a minima at the point theta_s=0 and theta_d=pi\n",
      "B0 = 0.011780972450961723\n"
     ]
    }
   ],
   "source": [
    "print(\"Value of B0 for which the potential U turns into a minima at the point theta_s=0 and theta_d=pi\\nB0 =\",\n",
    "      3*mu_d_max*u_0/(4*np.pi*d**3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining potential energy U functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def U_int(th_s,th_d, mu_d):\n",
    "    '''Potential function of the demon system interaction'''\n",
    "    return mu_d*u_0*mu_s/(4*np.pi*d**(3)) * (np.cos(th_s)*np.cos(th_d) - 2*np.sin(th_s)*np.sin(th_d))\n",
    "\n",
    "@njit\n",
    "def U_system(th_s):\n",
    "    '''Potential of the system coil interaction'''\n",
    "    return -mu_s*B_0*np.cos(th_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum potential energy of the system and coil\n",
      "U_0   minimum: -6.283185307179586e-17\n",
      "The minimum potential energy of the demon and system intreaction\n",
      "U_int minimum: -1.2337005501361697e-17\n"
     ]
    }
   ],
   "source": [
    "U_0_min = U_system(0)\n",
    "U_int_min = U_int(0,-np.pi,mu_d_max) # this isnt really the minimum of that function :) but the ths=0 and thd=PI point, it would be the zero point of the combined potential energy\n",
    "print(\"The minimum potential energy of the system and coil\\nU_0   minimum:\", U_0_min)\n",
    "print(\"The minimum potential energy of the demon and system intreaction\\nU_int minimum:\", U_int_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring correlation between the demon and system\n",
    "There is a covariance function that measures the correlation between two random variables.\n",
    "$$cov(\\theta_s,\\theta_d)=〈\\theta_s\\theta_d〉-〈\\theta_s〉〈\\theta_d〉$$\n",
    "and then there is the correlation coefficient which is a good measure of how much the variables are correlated.\n",
    "$$cor(\\theta_s,\\theta_d)= \\frac{cov(\\theta_s,\\theta_d)}{\\sqrt{var(\\theta_s)*var(\\theta_d)}}$$\n",
    "\n",
    "The correlation takes values between -1 and 1. It goes from anticorrelated for -1 to not correlated at all/independend at 0 and maximaly correlated at 1.\n",
    "The arrays of angles at different times should suffice to calculate all the above quantities.\n",
    "I would like to return to the correlation measure and try to get a better understanding why it gives a reliable measure of extend to which the two variables are correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.8054140358893986\n"
     ]
    }
   ],
   "source": [
    "def covariance(x,y):\n",
    "    '''calculates the covariance between two variables, could have used the native numpy implementation of this function, but nevermind'''\n",
    "    x_avg = np.average(x)\n",
    "    y_avg = np.average(y)\n",
    "    xy_avg = np.average(x*y)\n",
    "    return xy_avg - x_avg*y_avg\n",
    "\n",
    "def correlation(x,y):\n",
    "    '''outputs the correlation coefficient of two random variables'''\n",
    "    return covariance(x,y)/np.sqrt(np.var(x)*np.var(y))\n",
    "\n",
    "cor = correlation(solution[0,0],solution[1,0])\n",
    "print(\"Correlation:\",cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that the correlation and covariance functions work as intended. The correlation of almost -0.8 seems very high for $dt=10^{-9}$, but I suppose that it is correct. \n",
    "\n",
    "Using this covariance measure as the only measure of correlation between the two random variables can give us a wrong perception of the actual correlation. As seen in one of the ML textbooks, there are cases when the two variables are correlated or connected in a way that slips the detection through the covariance measure which is supposedly linear in a way. \n",
    "\n",
    "Another way to improve our intuition on the magnet's strength of coupling would be to plot a scatter and to calculate the mutual information as proposed by Ford."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the average correlation over multiple runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_avg(init,t_points,runs, langevin):\n",
    "    '''Calculates the correlation coefficient of the demon and system angles over multiple runs and averages those results\n",
    "    Parameters\n",
    "    ----------\n",
    "    runs: number of runs of solving the equations'''\n",
    "    cors = np.empty(runs, dtype='float64') # stors the correlation coefficients for each run\n",
    "    \n",
    "    for run in range(runs): \n",
    "        solution = langevin(init,t_points, cpl_period = 1/100000) # fast coupling, want to measure the correlation only when the magnets are fully coupled\n",
    "        cor = correlation(solution[0,0],solution[1,0])\n",
    "        cors[run] = cor\n",
    "\n",
    "    return np.average(cors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23092d549e1467bb3230c072c7f50f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_scatter(sol):\n",
    "    'plots a scatter plot of the demon and system angles'\n",
    "    plt.figure()\n",
    "\n",
    "    plt.scatter(sol[0,0],sol[1,0], s=2, color = (0.2, 0.5, 0.4), alpha = 0.01)\n",
    "    plt.xlabel(\"$\\\\theta_s (rad)$\")\n",
    "    plt.ylabel(\"$\\\\theta_d (rad)$\")\n",
    "    plt.title(\"Scatter plot\")\n",
    "\n",
    "plot_scatter(langevin(init, t_steps(1e-4, 1e5)))\n",
    "plt.savefig(\"1.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is somewhat informative in a way that it tells us that the magnet's angles really are linearly dependent to a certain approximation validity I guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divergence of the equations of motion\n",
    "The demon's solution started diverging at about $dt=5.2*10^{-8}s$ which is very close to the theoretical value calculated below when only resistance term was cosidered. We had to go much further with the dt for the system to also diverge. It did so somewhere around the $6.5*10^{-8}s$. It could have been a bit sooner but that is not important, what matters is that the dt at which the solutions diverges is approximately around the range of the theoreticaly calculated values given below. The system was less prone to diverging because its movement is additionaly modulated by the $B_0$ field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demon  dt: 5.173017847809882e-08\n",
      "system dt: 5.622083333333331e-08\n"
     ]
    }
   ],
   "source": [
    "max_dt_s = 2*I_s/gam_s\n",
    "max_dt_d = 2*I_d/gam_d\n",
    "print(\"demon  dt:\", max_dt_d)\n",
    "print(\"system dt:\", max_dt_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of the demon's orientation with respect to its minimum energy angle\n",
    "This will give us a rough idea of how closely the demon follows the system's magnetic orientation. This should be a good measure of it beacuse once the system magnet moves out of its equilibrium the demon's minimum energy state changes, if the demon was perfectly copying the system's motion we would always find it in this minim angle state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f927a43d7ed40e5a84d18ac90959a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_correlation(sol, t_points):\n",
    "    '''plots the demons angle trajectory in comparison to its minimum potential angle trajectory'''\n",
    "    th_d_follow = np.arctan(-2*np.tan(sol[0,0])) + np.pi # had to shift this by -pi because of the range of tan and arctan values\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.plot(t_points,sol[1,0], label=\"demon\")\n",
    "    plt.plot(t_points,th_d_follow, label=\"system\")\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"t (s)\")\n",
    "    plt.ylabel(\"$\\\\theta_d$\"+\" (rad)\")\n",
    "    plt.title(\"Demon following system\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    \n",
    "plot_correlation(solution, t_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah that epxlains why the correlation between the two angles was so high. The demon is doing a good job in following the system's movement but is not as quick to sudden changes of direction. The graph above really isn't really comparing the demon's and system's angles but rather the demon's angle with what the demon's angle would be if it was perfectly coupled to system and follow it instantaneously. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Langevin numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def langevin_numba(r,  t_points, cpl_period = 1/5, dcpl_period = 0,  coupling = 'linear'):\n",
    "    ''' Solves the differential equations and returns an array containing the angle trajectories with all the velocities\n",
    "    Parameters\n",
    "    ----------\n",
    "    r: is a vector containing  the initial boundary values r = [[theta_s, w_s],\n",
    "                                                                [theta_d, w_d]]\n",
    "    cpl_period: a fraction of time it takes to couple the demon to the system, originaly 1/5, default is the original\n",
    "    dpl_period: a fraction of time it takes to decouple the demon from system, default 0, instantaneous decoupling\n",
    "    coupling: type of coupling, linear, and exponential were implemented so far\n",
    "    t_points: array of t points to solve the equations for\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    sol: (2,2,t_points.size) array containing the solved angles and velocities\n",
    "    \n",
    "    '''\n",
    "    # initializing empty arrays that will store the resulting trajectories\n",
    "    theta_s = np.empty(t_points.shape)\n",
    "    theta_d = np.empty(t_points.shape)\n",
    "    w_s = np.empty(t_points.shape)\n",
    "    w_d = np.empty(t_points.shape)\n",
    "    \n",
    "    # t final\n",
    "    t_f = t_points[-1]\n",
    "    h = t_f/(len(t_points)-1)\n",
    "    \n",
    "    # storing the initial values\n",
    "    theta_s[0] = r[0,0]\n",
    "    theta_d[0] = r[1,0]\n",
    "    w_s[0] = r[0,1]\n",
    "    w_d[0] = r[1,1]\n",
    "\n",
    "    # solving the dif-eq\n",
    "    for idx in range(1,len(t_points)):\n",
    "        t = t_points[idx]\n",
    "        # abreviation for variables at t\n",
    "        th_s_t =  theta_s[idx-1]\n",
    "        th_d_t = theta_d[idx-1]\n",
    "        w_s_t = w_s[idx-1]\n",
    "        w_d_t = w_d[idx-1]\n",
    "        # calculate the variables at t+dt\n",
    "        theta_s[idx] = th_s_t + h*w_s_t\n",
    "        theta_d[idx] = th_d_t + h*w_d_t\n",
    "        w_s[idx] = (w_s_t + h*S1*mu_d_numba(t,t_f, cpl_period, dcpl_period = dcpl_period, coupling = coupling)*(np.sin(th_s_t)*np.cos(th_d_t) + 2*np.sin(th_d_t)*np.cos(th_s_t)) -\n",
    "                            h*S2*np.sin(th_s_t) -\n",
    "                            h*S3*w_s_t +\n",
    "                            h**(1/2)*S4*np.random.normal()  \n",
    "                    )\n",
    "        w_d[idx] = (w_d_t + h*D1*mu_d_numba(t,t_f, cpl_period, dcpl_period = dcpl_period,  coupling = coupling)*(np.sin(th_d_t)*np.cos(th_s_t) + 2*np.sin(th_s_t)*np.cos(th_d_t)) -\n",
    "                            h*D2*w_d_t  +\n",
    "                            h**(1/2)*D3*np.random.normal()  \n",
    "                   )\n",
    "        \n",
    "    sol = np.empty((2,2, t_points.shape[0]))\n",
    "    sol[0,0] = theta_s\n",
    "    sol[0,1] = w_s\n",
    "    sol[1,0] = theta_d\n",
    "    sol[1,1] = w_d\n",
    "    \n",
    "    return sol\n",
    "\n",
    "@njit\n",
    "def mu_d_numba(t, t_f, cpl_period, coupling = 'linear', dcpl_period = 0):\n",
    "    \"\"\"calculates the magnetic moment of the demon paramagnet\n",
    "    Parameters\n",
    "    ----------\n",
    "    t_f: final time of the time interval period\n",
    "    coupling: type of coupling chosen, LINEAR, EXPONENTIAL\n",
    "    \"\"\"\n",
    "    \n",
    "    # turning on coupling\n",
    "    if (t <= t_f*cpl_period):\n",
    "        # linear coupling, default\n",
    "        if (coupling == 'linear'):\n",
    "            alpha = mu_d_max / (t_f*cpl_period)    \n",
    "            return alpha*t\n",
    "        \n",
    "        # exponential coupling\n",
    "        elif (coupling == 'exp'):\n",
    "            gam = 10 / (cpl_period*t_f)\n",
    "            #if t > t_p[int(N*cpl_period/10 - 5)] and t < t_p[int(N*cpl_period/10)]:\n",
    "                #print(mu_d_max * (1 - np.exp(-gam*t)))\n",
    "            return mu_d_max * (1 - np.exp(-gam*t))\n",
    "    \n",
    "    # decoupling\n",
    "    elif (t > t_f*(1-dcpl_period)):\n",
    "        # linear coupling \n",
    "        if (coupling == 'linear'):\n",
    "            alpha = mu_d_max / (t_f*dcpl_period) \n",
    "            return mu_d_max - alpha*(t - t_f*(1-dcpl_period))\n",
    "        # exponential decoupling\n",
    "        elif (coupling == 'exp'):\n",
    "            gam = 10 / (t_f*dcpl_period)\n",
    "            return mu_d_max * np.exp(-gam*(t - t_f*(1-dcpl_period)))\n",
    "            \n",
    "            \n",
    "    # max coupling  \n",
    "    else:\n",
    "        return mu_d_max # m = Md*V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_p = t_steps(1e-5, 1e6)\n",
    "r1 = np.array([[0,0],[0,0]])\n",
    "sol_exp = langevin_numba(init, t_p,\n",
    "                         cpl_period = 1/5,\n",
    "                         dcpl_period = 1/5,\n",
    "                         coupling = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532593f4d4004f6db110e16624731e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot_angles(sol_exp, t_p)\n",
    "plot_correlation(sol_exp, t_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking numba version of the langevin function\n",
    "Unbeliveable that we the function gets sped up by 200 times and the for loop seems to stay untouched, it still computes it it in series. I mean this still seems to big of an improvement for a nonparallelized for loop. It is tricky to validate the numba implementation of the function because of the np.random which causes each solution of the equations to be unique. One thing that I was worried about was that the for loop inside the @njit decorator gets subdivided into multiple parts and evaluated simultaneously in parallel which just cant be done when solving a time evolving equations of motion. If this would be happening that I suspected that there would be jumps in the solutions since for the first elemnt in each section it would have to take the previous element which was not yet computed and set by np.empty to very small value. This cant be seen in the graphs. Moreover I put a print statements inside that executed every 10 iterations and they executed in sequence. Well I might try to look into this tomorrow. One more thing that sort of points in the direction that the function works as intended is the fact that it produces same correlations as normal implementation over the entire range of dts that were tested. There was still something odd happening when evaluating the functions (have to make sure that all variables got updated). \n",
    "\n",
    "When parallel se to True, it outputs an error message that there was nothing that could be parallelized. The function still runs and takes the same amount of time to execute. Additionaly, I ran the langevin numba function again with print statements inside but now printing on each iteration and it was printing the values in sequence again. I tried this logic on a simple function that was parallelized with parallel = True and used prange and indeed the print statements did not execute in sequence. Though the prange had to be included otherwise the for loop did not get parallelized. Alright this should settle down my worries of the langevin not executing in series.\n",
    "\n",
    "And final remark, python for loops are unbeliveably slow if numba can speed them up by a factor of 250 without parallelizing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4 ms ± 370 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.77 s ± 1.12 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit langevin_numba(init, t_points)\n",
    "%timeit langevin(init, t_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By getting rid of the if statement and looping over a range of indecis instead of enumerate the execution time for classical langevin equation was brougt down from 4 to 2.7s, the numba implementationdid not change almsot at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average correlation over multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average correlation coefficient value: -0.6944632253757639\n"
     ]
    }
   ],
   "source": [
    "t_points4 = t_steps(10**(-5), int(1e6))\n",
    "cor_avg_many = cor_avg(init, t_points4,50, langevin_numba)\n",
    "print('The average correlation coefficient value:',cor_avg_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equilibrium miscrostate probability of demon and system\n",
    "when the coupling is fully turned on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_long = t_steps(10**(-3), int(1e7))\n",
    "sol_pdf = langevin_numba(init, t_long, cpl_period = 1/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1b4974491549d7b57efaed7bd5b57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot_angles(sol_pdf, t_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e7fed65e684e80970fdde8dbfd8fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demon's pdf\n",
      "mean:  3.1402093846638888 \n",
      "std:   0.03127744727933691\n",
      "System's pdf\n",
      "mean:  0.0005601544354923203 \n",
      "std:   0.012804431800403252\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10.5, 4.2))\n",
    "\n",
    "num_bins = 40\n",
    "plt.subplot(1,2,1)\n",
    "n, bins, patches = plt.hist(sol_pdf[1,0][-int(9e6):], num_bins)\n",
    "plt.xlabel('$\\\\theta_d$')\n",
    "plt.ylabel('counts')\n",
    "plt.title('$\\\\theta_d$ equilibrium distribution')\n",
    "plt.subplot(1,2,2)\n",
    "n, bins, patches = plt.hist(sol_pdf[0,0][-int(9e6):], num_bins)\n",
    "plt.xlabel('$\\\\theta_s$')\n",
    "plt.ylabel('counts')\n",
    "plt.title('$\\\\theta_s$ equilibrium distribution')\n",
    "pdf_s_std = np.std(sol_pdf[0,0][-int(9e6):])\n",
    "pdf_d_std = np.std(sol_pdf[1,0][-int(9e6):])\n",
    "print(\"Demon's pdf\\nmean: \", np.mean(sol_pdf[1,0][-int(9e6):]), \"\\nstd:  \" , pdf_d_std)\n",
    "print(\"System's pdf\\nmean: \", np.mean(sol_pdf[0,0][-int(9e6):]), \"\\nstd:  \" ,pdf_s_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Mean rotatinal kinetic energy\n",
    "compared to $kT/2$ which it should equal to according to equipartition theorem and also by construction of langevin equations because it the fluctuating and resistive terms were set such that they satisfy this statistical property of particles in equilibrium with a heat bath/rest of the fluid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 run \n",
      "Average kinetic energy over coupling and stationary period (mu_d does not change)\n",
      "<Ek> of the system: 1.0545104145042066\n",
      "<Ek> of the demon : 1.051421089545789\n",
      "kT/2              : 1\n",
      "Average kinetic energy over stationary period\n",
      "<Ek> of the system: 1.070107577513761\n",
      "<Ek> of the demon : 1.0398045578638884\n"
     ]
    }
   ],
   "source": [
    "@njit(['float64(float64[:], float64)'])\n",
    "def avg_KE(w,I):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    w: an array of angular velocities, usually solved over 1 run\n",
    "    I: the moment of inerta\n",
    "    Funny that numba does not yet know yet how to convert np.average to machine code but has no problem with np.mean\n",
    "    '''\n",
    "    E_k = 1/2*I*w**2\n",
    "    return np.mean(E_k)\n",
    "\n",
    "sol = langevin_numba(init, t_points, cpl_period = 1/5)\n",
    "KE = avg_KE(sol[0,1],I_s)\n",
    "KE_D = avg_KE(sol[1,1],I_d)\n",
    "print('1 run \\nAverage kinetic energy over coupling and stationary period (mu_d does not change)')\n",
    "print('<Ek> of the system:',KE*2/E_unit)\n",
    "print('<Ek> of the demon :',KE_D*2/E_unit)\n",
    "print('kT/2              :',1)\n",
    "print('Average kinetic energy over stationary period')\n",
    "print('<Ek> of the system:',avg_KE(sol[0,1][int(N/5):],I_s)*2/E_unit)\n",
    "print('<Ek> of the demon :',avg_KE(sol[1,1][int(N/5):],I_d)*2/E_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel = True)\n",
    "def avg_KE_stats(n, runs, t_points, N, langevin, cpl_period = 1/5, coupling = 'linear'):\n",
    "    ''' average of average of averages,\n",
    "    Outputs n averaged kinetic energies each averaged over #runs of runs of the solutions\n",
    "    Calculates the average kinetic energies over the coupling period and over the stationary period at max coupling separately.\n",
    "    Parameters\n",
    "    ----------\n",
    "    runs: is the number of runs per each cycle\n",
    "    n: number of cycles, in each cycle #runs of runs are executed  \n",
    "    '''\n",
    "    # stores the average kinetic energies of each cycle (coupling period included)\n",
    "    KE_cycle_couple_s = np.empty(n)\n",
    "    KE_cycle_couple_d = np.empty(n)\n",
    "    \n",
    "    # stationary period\n",
    "    KE_cycle_stat_s = np.empty(n)\n",
    "    KE_cycle_stat_d = np.empty(n)\n",
    "    \n",
    "    # potential energy\n",
    "    U_cycle = np.empty(n)\n",
    "    \n",
    "    for cycle in prange(n):\n",
    "        # stores the average kinetic energies of each run/solution\n",
    "        KE_run_couple_s = np.empty(runs)\n",
    "        KE_run_couple_d = np.empty(runs)\n",
    "        \n",
    "        # stationary period\n",
    "        KE_run_stat_s = np.empty(runs)\n",
    "        KE_run_stat_d = np.empty(runs)\n",
    "        \n",
    "        #U_run = np.empty(runs)\n",
    "        \n",
    "        for run in prange(runs):\n",
    "            sol = langevin(init, t_points, cpl_period = cpl_period, coupling = coupling)\n",
    "            KE_run_couple_s[run] = avg_KE(sol[0,1][:int(N/5)], I_s)\n",
    "            KE_run_couple_d[run] = avg_KE(sol[1,1][:int(N/5)], I_d)\n",
    "            \n",
    "            KE_run_stat_s[run] = avg_KE(sol[0,1][int(N/5):], I_s)\n",
    "            KE_run_stat_d[run] = avg_KE(sol[1,1][int(N/5):], I_d)\n",
    "            #U_run[run] = \n",
    "            \n",
    "        # after all the runs of this cycle are computed we can take the next average :)    \n",
    "        KE_cycle_couple_s[cycle] = np.mean(KE_run_couple_s)\n",
    "        KE_cycle_couple_d[cycle] = np.mean(KE_run_couple_d)\n",
    "        KE_cycle_stat_s[cycle] = np.mean(KE_run_stat_s)\n",
    "        KE_cycle_stat_d[cycle] = np.mean(KE_run_stat_d)\n",
    "        \n",
    "    return KE_cycle_couple_s, KE_cycle_couple_d, KE_cycle_stat_s, KE_cycle_stat_d        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the statitics of average kinetic energies over set of multiple runs each called a cycle 100x100 solutions of langevin\n",
    "KE_100_couple_s, KE_100_couple_d, KE_100_stat_s, KE_100_stat_d = avg_KE_stats(10,100, t_points, N, langevin_numba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100x100 runs\n",
      "Average and std of 100 cycles of averaged kinetic energies over 100 runs of langevin equations \n",
      "System\n",
      "max coupling    : 1.02072 +/- 0.00229\n",
      "during coupling : 1.02014 +/- 0.00336 \n",
      "Demon\n",
      "max coupling    : 1.02345 +/- 0.00276\n",
      "during coupling : 1.02191 +/- 0.00416\n"
     ]
    }
   ],
   "source": [
    "# Energies expressed in units of kT/2\n",
    "print('100x100 runs\\nAverage and std of 100 cycles of averaged kinetic energies over 100 runs of langevin equations \\nSystem')\n",
    "print('max coupling    : {0:.5f} +/- {1:.5f}'.format( np.average(KE_100_stat_s)*2/E_unit, np.std(KE_100_stat_s)*2/E_unit) )\n",
    "print('during coupling : {0:.5f} +/- {1:.5f}'.format( np.average(KE_100_couple_s)*2/E_unit, np.std(KE_100_couple_s)*2/E_unit),  '\\nDemon') \n",
    "\n",
    "print('max coupling    : {0:.5f} +/- {1:.5f}'.format( np.average(KE_100_stat_d)*2/E_unit, np.std(KE_100_stat_d)*2/E_unit) )\n",
    "print('during coupling : {0:.5f} +/- {1:.5f}'.format( np.average(KE_100_couple_d)*2/E_unit, np.std(KE_100_couple_d)*2/E_unit) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above I measured some statistical properties of the rotational kinetic energies of the system and demon during two separate periods, first while the coupling is turned on maximum and does not change and for second period which is 'during coupling' period that takes place while coupling is beng turned on from 0 to $kT/2$.\n",
    "\n",
    "Clearly the mean average kinetic energies over the two period are very close and agree within the 1 standard deviation, this gives us a clue that the coupling process does not affect the average kinetic energies as much and it definitely does not explain the 2% discrepency with the equipartition theorem. Still interesting to notice that the coupling period gets closer to the equipartition theorem (I ran this multiple times and it seemed to be the case even thought the std is quite high).\n",
    "\n",
    "Let's try to decrease the time step $dt$ and and see if the average kinetic energy gets closer to what it is supposed to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the average kinetic energies again but now with shorter dt \n",
    "N1 = int(1e5)\n",
    "t_f1 = 10**(-5)\n",
    "t_points_1 = t_steps(t_f1,N1)\n",
    "KE_100_couple_s1, KE_100_couple_d1, KE_100_stat_s1, KE_100_stat_d1 = avg_KE_stats(10,100, t_points_1, N1, langevin_numba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100x100 runs\n",
      "Average and std of 100 cycles of averaged kinetic energies over 100 runs of langevin equations \n",
      "System\n",
      "max coupling    : 0.99769 +/- 0.00614\n",
      "during coupling : 0.99237 +/- 0.01280 \n",
      "Demon\n",
      "max coupling    : 1.00280 +/- 0.00629\n",
      "during coupling : 1.00714 +/- 0.01820\n"
     ]
    }
   ],
   "source": [
    "# Energies expressed in units of kT/2\n",
    "print('100x100 runs\\nAverage and std of 100 cycles of averaged kinetic energies over 100 runs of langevin equations \\nSystem')\n",
    "print('max coupling    : {0:.5f} +/- {1:.5f}'.format( np.average(KE_100_stat_s1)*2/E_unit, np.std(KE_100_stat_s1)*2/E_unit) )\n",
    "print('during coupling : {0:.5f} +/- {1:.5f}'.format( np.average(KE_100_couple_s1)*2/E_unit, np.std(KE_100_couple_s1)*2/E_unit),  '\\nDemon') \n",
    "\n",
    "print('max coupling    : {0:.5f} +/- {1:.5f}'.format( np.average(KE_100_stat_d1)*2/E_unit, np.std(KE_100_stat_d1)*2/E_unit) )\n",
    "print('during coupling : {0:.5f} +/- {1:.5f}'.format( np.average(KE_100_couple_d1)*2/E_unit, np.std(KE_100_couple_d1)*2/E_unit) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean kinetic energies of both system and demon agree up to 2 significant digits with the $kT/2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dt was decreased by a factor of $10^{-3}$ and there is no clear improvement in terms of the kinetice energy approaching what is predicted by equipartition theorem. The coupling a fully coupled period do seem to exhibit a slight difference but that is still negligible. - This was due to a bug in the code.\n",
    "\n",
    "HYPOTHESIS: Okay so we assumed that the average kinetic energy of the magnet will be equal to $kT/2$ as it was stated by equipartition theorem, but that is not what the theorem says. It states that when ... maybe not\n",
    "\n",
    "Okay so the 2 percent discrepency between still has not been resolved and we came up with several guesses of what might the cause of it. \n",
    "\n",
    "1. The np.random.normal function might be outputing truly random numbers\n",
    "\n",
    "\n",
    "I checked that and it pretty much does, the std and mean both matched for and average and std over $10^8$ of these randomly drawn numbers the average and standard deviation agree up to an error of 5 significant figures, the mean was with an error of $10^{-5}$. Same results obtained when the random function was called from within a numba decorator.\n",
    "\n",
    "2. There is mistake/typo in the code or in the derivation of the equations of motion themself.\n",
    "\n",
    "3. The method for numericaly solving the equations is not accurate enough.\n",
    "\n",
    "The kinetic energies consistenly are higher than what they should be, the demon always overshoots more than the system magnet which might suggest that the more the magnets are allowed to move the more their kinetic energy exceeds the equipartition theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean kinetic energy of free magnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def langevin_free(r,t_points, cpl_period = 0, coupling = 'None'):\n",
    "    ''' Calculates the right hand sight of diff eqs for free to move magnets, no potential interactions\n",
    "    r is a vector containing r = [[theta_s, w_s],\n",
    "                                  [theta_d, w_d]]\n",
    "    I had to make this function accept cpl period and coupling so we do not get error when this function gets called inside the avg_KE_stat,\n",
    "    '''\n",
    "    # initializing empty arrays that will store the resulting trajectories\n",
    "    theta_s = np.empty(t_points.shape)\n",
    "    theta_d = np.empty(t_points.shape)\n",
    "    w_s = np.empty(t_points.shape)\n",
    "    w_d = np.empty(t_points.shape)\n",
    "    \n",
    "    # t final\n",
    "    t_f = t_points[-1]\n",
    "    h = t_f/ (len(t_points) - 1)\n",
    "    # storing the initial values\n",
    "    theta_s[0] = r[0,0]\n",
    "    theta_d[0] = r[1,0]\n",
    "    w_s[0] = r[0,1]\n",
    "    w_d[0] = r[1,1]\n",
    "\n",
    "    # solving the dif-eq\n",
    "    for idx in range(1,len(t_points)): \n",
    "        # abreviation for variables at t\n",
    "        th_s_t =  theta_s[idx-1]\n",
    "        th_d_t = theta_d[idx-1]\n",
    "        w_s_t = w_s[idx-1]\n",
    "        w_d_t = w_d[idx-1]\n",
    "        # calculate the variables at t+dt\n",
    "        theta_s[idx] = th_s_t + h*w_s_t\n",
    "        theta_d[idx] = th_d_t + h*w_d_t\n",
    "        w_s[idx] = (w_s_t - h*S3*w_s_t  + h**(1/2)*S4*np.random.normal() )\n",
    "        w_d[idx] = (w_d_t - h*D2*w_d_t  + h**(1/2)*D3*np.random.normal() )\n",
    "        \n",
    "    sol = np.empty((2,2, t_points.shape[0]))\n",
    "    sol[0,0] = theta_s\n",
    "    sol[0,1] = w_s\n",
    "    sol[1,0] = theta_d\n",
    "    sol[1,1] = w_d\n",
    "    \n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8035babf13547d180c40c627071b320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation: -0.49046645489412793\n"
     ]
    }
   ],
   "source": [
    "sol_free = langevin_free(init, t_points)\n",
    "plot_angles(sol_free,t_points)\n",
    "print('correlation:',correlation(sol_free[0,0],sol_free[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "KE_free_s1, KE_free_d1, KE_free_s2, KE_free_d2 = avg_KE_stats(10,100, t_points_1, N1, langevin_free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "<KE_cycle>:0.99992 +/- 0.00735\n",
      "demon\n",
      "<KE_cycle>:0.99785 +/- 0.00914\n"
     ]
    }
   ],
   "source": [
    "KE_free_s_avg = np.average( (KE_free_s1 + 4*KE_free_s2)/(5*E_unit) )*2\n",
    "KE_free_d_avg = np.average( (KE_free_d1 + 4*KE_free_d2)/(5*E_unit) )*2\n",
    "KE_free_s_std = np.std( (KE_free_s1 + 4*KE_free_s2)/(5*E_unit) )*2\n",
    "KE_free_d_std = np.std( (KE_free_d1 + 4*KE_free_d2)/(5*E_unit) )*2\n",
    "\n",
    "print('system\\n<KE_cycle>:{0:.5f} +/- {1:.5f}'.format(KE_free_s_avg ,KE_free_s_std ) )\n",
    "print('demon\\n<KE_cycle>:{0:.5f} +/- {1:.5f}'.format(KE_free_d_avg, KE_free_d_std ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KE over a single run with high number of steps N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "<KE_cycle>:0.99703\n",
      "demon\n",
      "<KE_cycle>:1.00196 \n"
     ]
    }
   ],
   "source": [
    "N2 = int(1e7)\n",
    "t_f2 = 10**(-3)\n",
    "t_points2 = t_steps(t_f2, N2)\n",
    "\n",
    "sol2 = langevin_free(init,t_points2)\n",
    "print('system\\n<KE_cycle>:{0:.5f}'.format( (avg_KE(sol2[0,1],I_s))*2/E_unit  ) )\n",
    "print('demon\\n<KE_cycle>:{0:.5f} '.format( (avg_KE(sol2[1,1],I_d))*2/E_unit  ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average potential energy of the magnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function that calculates the average potential energy per run\n",
    "@njit(parallel = True)\n",
    "def U_avg(sol,t_points,cpl_period = 1/5):\n",
    "    ''' It is easiest to measure it over the max coupling period\n",
    "    '''\n",
    "    N = t_points.shape[0]\n",
    "    u_len = int(N*(1-cpl_period)) # length of the max coupling period\n",
    "    i_shift = int(N*cpl_period)   # start index of the max coupling period\n",
    "    \n",
    "    u_sys = np.zeros(u_len)\n",
    "    u_int = np.zeros(u_len)\n",
    "    \n",
    "    tf = t_points[-1]\n",
    "    for i in prange(u_len):\n",
    "        u_sys[i] = U_system(sol[0,0][i+i_shift])\n",
    "        u_int[i] = U_int(sol[0,0][i+i_shift], sol[1,0][i+i_shift], mu_d_numba(t_points[i+i_shift], tf, cpl_period = cpl_period))\n",
    "        \n",
    "    u_tot = u_sys + u_int\n",
    "\n",
    "    return np.mean(u_sys), np.mean(u_int), np.mean(u_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.049423378965749\n"
     ]
    }
   ],
   "source": [
    "umean = U_avg(sol,t_points)[-1]\n",
    "print( (umean - U_0_min - U_int_min)/E_unit) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def U_avg_stats(n, runs, langevin):\n",
    "    '''Calculates the average potential energy over n cycles of #runs of runs, it calculates the avg potential energy only over the fully coupled period\n",
    "    from N/5 to N steps\n",
    "    !!!! There is something odd happening when the outer loop gets parallelized with prange(), might want to investigate why we were getting 10^50 as avg values\n",
    "    of the potential energy, it makes me worried because we used an exactly same code structure for the avg KE but fortunately it did not break. Might want to\n",
    "    get a better understand what is this cause by. !!!!\n",
    "    '''\n",
    "    U_tot_cycles = np.zeros(n)\n",
    "    U_sys_cycles = np.zeros(n)\n",
    "    U_int_cycles = np.zeros(n)\n",
    "    \n",
    "    for cycle in range(n):\n",
    "        U_tot_runs = np.zeros(runs)\n",
    "        U_sys_runs = np.zeros(runs)\n",
    "        U_int_runs = np.zeros(runs)\n",
    "        \n",
    "        for run in prange(runs):\n",
    "            sol = langevin(init, t_points_1)\n",
    "            U_sys_runs[run], U_int_runs[run], U_tot_runs[run] = U_avg(sol, t_points_1)\n",
    "            \n",
    "        U_tot_cycles[cycle] = np.mean(U_tot_runs)\n",
    "        U_int_cycles[cycle] = np.mean(U_int_runs)\n",
    "        U_sys_cycles[cycle] = np.mean(U_sys_runs)\n",
    "    \n",
    "    return U_sys_cycles, U_int_cycles, U_tot_cycles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<U_int>: -0.20267 +/- 0.03878\n",
      "<U_sys>: 1.19468 +/- 0.06534\n",
      "<U_tot>: 0.99201 +/- 0.03128\n"
     ]
    }
   ],
   "source": [
    "uavg = U_avg_stats(10, 100, langevin_numba)\n",
    "\n",
    "print(\"<U_int>: {0:.5f} +/- {1:.5f}\".format( np.average(uavg[1]- U_int_min)/E_unit , np.std(uavg[1]- U_0_min)/E_unit ) )\n",
    "print(\"<U_sys>: {0:.5f} +/- {1:.5f}\".format( np.average(uavg[0]- U_0_min)/E_unit , np.std(uavg[0] - U_int_min)/E_unit ) )\n",
    "print(\"<U_tot>: {0:.5f} +/- {1:.5f}\".format( np.average(uavg[2]- U_0_min - U_int_min)/E_unit , np.std(uavg[2]- U_0_min - U_int_min)/E_unit ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems too good to be true. Very interesting to see that the average potential energy is very close to kT, each potential function contributes kT/2, one coming from the magnet magnet interaction and the other from the system interacting with the coil. Ian suggested that the sines and cosines in the potential fucntion can be expanded around its minima and approximated to second order which would give us a harmonic potential which would translate to kT/2 per quadratic term contribution to total average energy according to equipartition theorem. Well, computationaly we get close to it but analyticaly I was not able to derive such a result not even with tons of approximations. Would be interesting to see how much this changes as we deacrease the strength of the potentials and the magnets explore wider range of angles. \n",
    "\n",
    "The average of U_system which is the potential energy between system and coil is a reflection of a maximum energy that could be extracted on account of a perfect measurement of the state of the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.46 ms ± 329 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "236 µs ± 34.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit U_avg(sol,t_points)\n",
    "%timeit avg_KE(sol[0,1],I_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Energy cost of coupling \n",
    "For now we can implement a fucntion that takes in all the angles and calculates the energy cost, in future I might put this inside the langevin function or create a class and combine all this together and create a method/functions on that class.\n",
    "\n",
    "So if we abruptly set the demon's magnetic moment to zero after the coupling period the mean energy cost seemed like to be negative indicating tat more enrgy is flowing out of the system than into the system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.2332144220285172e-17\n"
     ]
    }
   ],
   "source": [
    "@njit()\n",
    "def work_couple_numba(solution, t_points, cpl_period = 1/5, coupling = 'linear'):\n",
    "    '''Parallelized version of the work function, important not to forget that this will produce slightly different\n",
    "    results compared to a serial evaluation of the work, because of float rounding. \n",
    "    I also made it include the N step because at Nth time step the coupling is not on its max value yet.\n",
    "    '''\n",
    "    N = len(t_points) - 1 # not a length of the tpoints but number of time intervals\n",
    "    t_f = t_points[-1]\n",
    "    dt = t_f/ N \n",
    "    \n",
    "    th_s = solution[0,0][:int(N*cpl_period)]\n",
    "    th_d = solution[1,0][:int(N*cpl_period)]\n",
    "\n",
    "    C = u_0*mu_s/(4*np.pi*d**(3))   # collection of constants\n",
    "    \n",
    "    W = 0  # total work done     \n",
    "\n",
    "    # du/dt\n",
    "    # linear\n",
    "    if (coupling == 'linear'):\n",
    "        alpha =  mu_d_max / (t_f*cpl_period)\n",
    "        dudt = np.full(th_s.size, alpha) # just creating an array of the same dudt values, this implementation needs to be changed\n",
    "\n",
    "    # exponential\n",
    "    elif (coupling == 'exp'):\n",
    "        gam = 10 / (t_f*cpl_period)\n",
    "        exp_arg = -gam*t_points[:int(N*cpl_period)]\n",
    "        dudt = mu_d_max * gam * np.exp(exp_arg)\n",
    "        \n",
    "    # evaluate the work\n",
    "    for i in prange(th_s.size):\n",
    "        W +=  C*( np.cos(th_s[i])*np.cos(th_d[i]) - 2*np.sin(th_s[i])*np.sin(th_d[i])) * dudt[i] * dt\n",
    "\n",
    "    return W\n",
    "\n",
    "cp = 1/5\n",
    "w_couple =  work_couple_numba(langevin_numba(init, t_points_1, cpl_period = cp), t_points, cpl_period = cp)   \n",
    "print(w_couple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work: -1.2339524888500346e-17\n"
     ]
    }
   ],
   "source": [
    "sol2 = langevin_numba(init, t_points_1, cpl_period = 1/5, coupling = 'exp')\n",
    "print('work:',work_couple_numba(sol2, t_points_1, cpl_period = 1/5, coupling = 'exp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This again something completely unexpected, if we make the coupling period shorter the energy we gain from coupling increases which is exact opposite of what we would expect. The more abrupt coupling the more wasteful and heat disipative it should be but instead we see a gain in energy. It makes a sense from the point of view that when we are making the coupling period smaller and smaller we are approching the limit where we the coupling period is 0 and the energy gained is maximized - the difference between the final and initial potential energies. But otherwise I have no clue how to explain this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def work_couple(solution, N ,t_f):\n",
    "    '''I am not using this function anymore, just keeping it here for reference, need to be careful about the h that does not change with t_points'''\n",
    "    alpha = mu_d_max*5/t_f\n",
    "    \n",
    "    th_s = solution[0,0][:int(N/5)]\n",
    "    th_d = solution[1,0][:int(N/5)]\n",
    "    \n",
    "    C = u_0*mu_s/(4*np.pi*d**(3))   # collection of constants\n",
    "    \n",
    "    W = 0    # total work done \n",
    "    for i in range(th_s.size):\n",
    "        W +=  C*( np.cos(th_s[i])*np.cos(th_d[i]) - 2*np.sin(th_s[i])*np.sin(th_d[i])) * alpha * h   \n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay this is unexpected, so I calculated the energy it takes to couple the system and magnet. Since they are already in their lowest energy, by turning on the magnetic moment of the demon we are decreasing the potential energy and the work that it takes to couple the demon with a system is therefore negative which just appears so odd at first sight. Now we will have to give the system energy to decouple it from the demon and that should be higher than the energy that we initially obtained from the system/heat bath. I dont know yet what to think about this. If the process of consuming a recovering energy from the enviroment is reversed, does it make sense to postulate that energy lost to the enviroment is quasistatic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking work function performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186 ms ± 29.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "703 µs ± 43.9 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit work_couple(solution, N ,t_f)\n",
    "%timeit work_couple_numba(solution, t_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numba version evaluates the function around 500 times faster which is a decent speed up. Well it used to be, but now when the fucntion is more complicated it is slower. The if branch slows it down by almsot a factor of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Mean energy cost of measurement\n",
    "Calculating the mean energy cost of coupling the demon with the system over multiple runs and thus obtaining a statistical average of this quantity. The initial positions of both magnets are always reset.\n",
    "\n",
    "\n",
    "I discovered that the interval over which the work was calculated was slightly of by 1 time step, so we did get an extra negative contribution from that time step during the coupling process which resulted in average energy cost being negative, still not sure why are we getting much.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit()\n",
    "def E_cost(n, t_points, cpl_period = 1/5, dcpl_period = 0, coupling = 'linear', pdf = 'previous'):\n",
    "    '''returns energy costs of coupling and decoupling the demon of n runs\n",
    "    Parameters\n",
    "    ----------\n",
    "    pdf: initializes the magnets positions an velocities\n",
    "        previous = sets it to values it had at the end of previous run\n",
    "        eq = randomly initializes the angles and velocities with boltzmans equilibrium distribution\n",
    "        zero = sets the velocities to zero, system's angle to zero and demon's angle to pi\n",
    "    '''\n",
    "    w_costs = np.empty(n)\n",
    "    w_couples = np.empty(n)\n",
    "    w_decouples = np.empty(n)\n",
    "    \n",
    "    init_r = init  # initializing \n",
    "    for run in range(n):\n",
    "        sol = langevin_numba(init_r, t_points, cpl_period=cpl_period, dcpl_period = dcpl_period, coupling = coupling)\n",
    "        \n",
    "        w_couple   = work_couple_numba(sol, t_points, cpl_period = cpl_period, coupling = coupling)   #  - energy change during coupling \n",
    "        w_decouple = work_decouple(sol, t_points, dcpl_period = dcpl_period, coupling = coupling)     #  + energy change during coupling\n",
    "        \n",
    "        w_couples[run] = w_couple\n",
    "        w_decouples[run] = w_decouple\n",
    "        w_costs[run] = w_couple + w_decouple\n",
    "        \n",
    "        #Specifying the initial angles and velcoities for the next run\n",
    "        # using the angles and velocites from previous run (instantaneous decoupling and extraction of energy)\n",
    "        if (pdf == 'previous'):\n",
    "            init_r = sol[:,:,-1]\n",
    "            \n",
    "        # angles randomized according to boltzman equilibrium distribution and the velocities set to zero, np.random.choice not recognized by numba\n",
    "        elif (pdf == 'eq'):\n",
    "            init_r = np.zeros((2,2))\n",
    "            th_d = np.random.random()*np.pi*2 - np.pi\n",
    "            th_s = np.random.normal()*pdf_s_std\n",
    "            init_r[0,0], init_r[1,0] = th_s, th_d\n",
    "            \n",
    "        # all zeros, zero velocities and angles at their respective minima\n",
    "        elif (pdf == 'zero'):\n",
    "            init_r = np.zeros((2,2))\n",
    "            init_r[1,0] = np.pi\n",
    "\n",
    "    return w_couples/E_unit, w_decouples/E_unit, w_costs/E_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit()\n",
    "def work_decouple(sol, t_points, dcpl_period = 0, coupling = 'linear'):\n",
    "    ''' calculates the work done during the decoupling process\n",
    "    the decoupling process starts at time step N(1-dcpl_period) + 1 even though the coupling is still 100% on, this is the first t point where the\n",
    "    slope of demon's magnetic moment starts decreasing and we have to include this step.\n",
    "    and we have to end at time step N because at N+1 the coupling should effectively come to zero. There was something weird happening with the indexing\n",
    "    of the sol and points arrays, so it was including the N+1 element inside the indexed arrays and that made the problem assymetric, 20001 decoupling points and \n",
    "    20000 coupling points, also by including the last point an additional contribution was made towards the + decoupling work\n",
    "    '''\n",
    "    N = int(t_points.size - 1) # Number of time intervals\n",
    "    t_f = t_points[-1]\n",
    "    dt = t_f/ N \n",
    "    \n",
    "    C = u_0*mu_s/(4*np.pi*d**(3))   # collection of constants\n",
    "    W = 0\n",
    "\n",
    "    # instantaneous decoupling \n",
    "    if (dcpl_period == 0):\n",
    "        th_s, th_d = sol[0,0][-1], sol[1,0][-1] # final values of th_d and th_s\n",
    "        return 0 - U_int(th_s, th_d, mu_d_max) # + energy lost to decouple \n",
    "    \n",
    "    # continuous decoupling \n",
    "    else:\n",
    "        th_d = sol[1,0][int(N*(1-dcpl_period)) : N]   # fucked up indexing :N+1 still included the N+1 element\n",
    "        th_s = sol[0,0][int(N*(1-dcpl_period)) : N]   # last element is not included (N+1)\n",
    "        \n",
    "        # linear coupling\n",
    "        if (coupling == 'linear'):\n",
    "            alpha = mu_d_max / (t_f*dcpl_period)\n",
    "            dudt = np.full(th_s.size, - alpha ) # just creating an array of the same dudt values, this implementation needs to be changed\n",
    "\n",
    "        # exponential\n",
    "        elif (coupling == 'exp'):\n",
    "            gam = 10 / (t_f*dcpl_period)\n",
    "            exp_arg = - gam * ( t_points[int(N*(1-dcpl_period)) : N] - t_f*(1-dcpl_period) )\n",
    "            dudt = - mu_d_max * gam * np.exp(exp_arg)\n",
    "\n",
    "        for i in prange(th_s.size):\n",
    "            W +=  C*( np.cos(th_s[i])*np.cos(th_d[i]) - 2*np.sin(th_s[i])*np.sin(th_d[i])) * dudt[i] * dt\n",
    "            \n",
    "    return W\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORK couple  : -1.2334007125911408e-17\n",
      "WORK decouple: 1.2335200066725644e-17\n",
      "U decouple: 1.233492065737014e-17\n"
     ]
    }
   ],
   "source": [
    "cpl = 1/5\n",
    "dcpl = 1/5\n",
    "solt = langevin_numba(init, t_points_1, cpl_period = cpl, dcpl_period = dcpl, coupling = 'linear')\n",
    "print('WORK couple  :', work_couple_numba(solt, t_points_1, cpl_period = cpl, coupling = 'linear'))\n",
    "print('WORK decouple:', work_decouple(solt, t_points_1, dcpl_period = dcpl, coupling = 'linear'))\n",
    "print('U decouple:', -U_int(solt[0,0][-1], solt[1,0][-1], mu_d_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran the E_cost function below with couplig and decoupling period 1/20, N was 10^7 and tf = 10^(-5) which makes the dt 10-12, for such a short period of coupling and decoupling the average energy cost of measurement was found to be 0.8 and 0.6 which closely relates to what we found for t_points4 but here the accuracy was 10 times higher with 500 000 time steps during both coupling and decoupling period which is a lot. If we ran this algorithm again with the same number of steps and tf then but for now a slightly lareger coupling and decoupling period of 1/5, if it produces the same mean energy cost of measurement as what we got for t_points4 with worse accuracy then it would suggest that the t_points4 is accurate enough and the unexpected trends cannot be explained by insufficient accuracy of our numerical methods. And yes this is what happend, morevover for cpl and dcpl periods of 1/5 we obtained similar results for t_points4 and t_points5, around 0.08 which I was also able to obtain with t_points_1 which is 100 times less accurate than t_points5, so yeah the method seems to be accurate enough for these t_points4 timesteps, what else is going on then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to run this with 10000 runs which will take about 1 and half hours, will do that while working out.\n",
    "t_points5 = t_steps(10**(-5), int(10**7))\n",
    "N3 = int(1e5)\n",
    "t_f3 = 10**(-5)\n",
    "t_points3 = t_steps(t_f3, N3)\n",
    "t_points4 = t_steps(10**(-5), int(1e6))\n",
    "W_many = E_cost(1000, t_points4, cpl_period = 1/5, coupling = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0f77a9fd5b440b92210c12db696e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 1.0709367609644929\n",
      "std : 1.5586458486974606\n"
     ]
    }
   ],
   "source": [
    "def plot_E_cost(E_costs):\n",
    "    '''Plots a histogram of the works done over early specified amount of trajectories'''\n",
    "    plt.figure()\n",
    "\n",
    "    num_bins = 40\n",
    "    n, bins, patches = plt.hist(E_costs, num_bins)\n",
    "    plt.xlabel('W (kT)')\n",
    "    plt.ylabel('counts')\n",
    "    plt.title('Energy cost of measurement')\n",
    "plot_E_cost(W_many[-1])\n",
    "print('mean:', np.average(W_many[-1]))\n",
    "print('std :', np.std(W_many[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On average for each time step dt the work done on the system is: 0.1524075850291405\n"
     ]
    }
   ],
   "source": [
    "print('On average for each time step dt the work done on the system is:',-U_int_min/E_unit/20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above number expressed in kT/2 units and for a coupling period of 20000 steps tells us that if we were to ommit one time step contribution to the final work done it would on average decrease by 0.3. Yeah so for dt = 10^(-10) the average energy cost of measurement is 0.4 in contrast to 0.1 for dt = 10^(-11) but calculated over the same time period with higher number of steps, 10 times more steps. This is still odd because it is not that we removed one timestep and the energy cost became less by the 0.3 difference but instead we icnceased the accuracy of the energy calcualted over the same time interval by increasing the nubmber of steps taken, does that suggests the accuracy of the first dt steps was not high enough, if so then how far can we push this? In a case of infinitesimal dt would the average energy cost of the measurement become 0? Also why is not zero in the first place, is that because we take more time steps during decoupling period than the coupling period?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we just decrease the dt and make the time interval smaller, thus making the coupling time shorter, would that give us higher mean? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_many_10 = E_cost(1000, t_points4, cpl_period=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b8f88872634a04a3f8f063704cb30a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.3017091657688983\n",
      "std : 1.7679672117014495\n"
     ]
    }
   ],
   "source": [
    "plot_E_cost(w_many_10[-1])\n",
    "print('mean:', np.average(w_many_10[-1]))\n",
    "print('std :', np.std(w_many_10[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quasistatic coupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpl_periods = np.arange(0.05, 1, 0.08)\n",
    "cpl_periods_long = np.concatenate( (np.arange(0.01,0.13,0.01), np.arange(0.1, 1, 0.04)) )\n",
    "\n",
    "@njit(parallel = True)\n",
    "def E_cost_quas_couple(n, t_points, pdf = 'previous', couple_periods = cpl_periods):\n",
    "    '''Energy cost of coupling averaged over n trajectories/runs for different coupling periods couple_periods, instantaneous decoupling\n",
    "    Parameters\n",
    "    ----------\n",
    "    couple_periods: numpy array containing the coupling periods for which to calcualte the E_cost\n",
    "    '''\n",
    "    E_cost_avg = np.empty(couple_periods.size) \n",
    "    w_cpl_avg = np.empty(couple_periods.size) \n",
    "    w_dcpl_avg = np.empty(couple_periods.size) \n",
    "    \n",
    "    for i in prange(couple_periods.size):\n",
    "        w_cpl, w_dcpl, E_costs =  E_cost(n ,t_points, cpl_period = couple_periods[i], pdf = pdf) \n",
    "        E_cost_avg[i] = np.mean(E_costs)\n",
    "        w_cpl_avg[i] = np.mean(w_cpl)\n",
    "        w_dcpl_avg[i] = np.mean(w_dcpl)\n",
    "        \n",
    "    return w_cpl_avg, w_dcpl_avg, E_cost_avg\n",
    "\n",
    "E_quasi = E_cost_quas_couple(100, t_points4, pdf = 'previous', couple_periods = cpl_periods_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c2a3cb425f45bf9c78df282558c4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(21,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(cpl_periods_long, E_quasi[-2], 'or')\n",
    "plt.title('⟨W⟩ decouple', fontsize= 20)\n",
    "plt.ylabel('E (kT)', fontsize= 15)\n",
    "plt.xlabel('$t_c/t_f$', fontsize= 15)\n",
    "plt.ylim(3048,3049)\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(cpl_periods_long, E_quasi[-3], 'og')\n",
    "plt.title('⟨W⟩ couple', fontsize= 20)\n",
    "plt.xlabel('$t_c/t_f$', fontsize= 15)\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(cpl_periods_long, E_quasi[-1] ,'o', c='darkorange')\n",
    "plt.xlabel('$t_c/t_f$', fontsize= 15)\n",
    "plt.ylabel('$ ⟨W_{cost}⟩$ (kT)', fontsize= 15)\n",
    "plt.title('Non-equilibrium demon', fontsize= 20)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58b9d59df014cb197a9ff448622bf33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(cpl_periods_long, E_quasi[-1] ,'o', c='darkorange')\n",
    "plt.xlabel('$t_c/t_f$')\n",
    "plt.ylabel('$ ⟨W_{cost}⟩$ (kT)')\n",
    "plt.title('Non-equilibrium demon')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I have already shown that the energy cost of measurement is accurately enough computed with the dts that we have used here, well I showed it for continuous coupling and decoupling but not for instantaneous decoupling but anyway the I have used t_points4 here and took an average over 1000 runs and still the average energy cost does go down for smaller coupling periods which is opposite of what we expected. This pretty much means that the faster we couple the system with the demon the more energy we are getting during the coupling period, if  we assume that the decoupling period's change in energy remains the same on average. That is strange, because a more quasistatic process should be able to get more energy out of the system during coupling and not the other way around. I still has no idea why are we seeing these results, it is not caused by insufficient accuracy, nor wrong specifications of the coupling and decoupling periods, or a mistake in the functions that calculate the work and solve the differential equations. I am going to leave this again and come back to this problem later, my understanding of the energy transfer processes is still very limited so I definitely want to read the Ian's section on the free energy and related topics so I can deal with this better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0001 0.0006 0.0011 0.0016 0.0021 0.0026 0.0031 0.0036 0.0041 0.0046\n",
      " 0.0051 0.0056 0.0061 0.0066 0.0071 0.0076 0.0081 0.0086 0.0091 0.0096]\n"
     ]
    }
   ],
   "source": [
    "cpl_periods1 = np.arange(0.0001, 0.01, 0.0005)\n",
    "E_cost_average1 = np.empty(cpl_periods1.size)\n",
    "print(cpl_periods1)\n",
    "\n",
    "#for i in range(cpl_periods1.size):\n",
    "#    E_cost_average1[i] = np.average( E_cost(1000,t_points4, cpl_period = cpl_periods1[i]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc2014d26404709877954500644f3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(cpl_periods1, E_cost_average1/E_unit, 'x')\n",
    "plt.xlabel('coupling period')\n",
    "plt.ylabel('average energy cost')\n",
    "plt.title('Quasistatic coupling')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantaneous decoupling \n",
    "$$\n",
    "\\Delta W = \\Delta E \\\\\n",
    "= \\Delta U + \\Delta E_{kinetic} \\\\\n",
    "= \\Delta U\n",
    "$$\n",
    "Quasistatic decoupling\n",
    "$$\n",
    "\\Delta W = \\Delta F \\\\\n",
    "= \\Delta E - T\\Delta S \\\\\n",
    "= \\Delta U - T\\Delta S \\\\\n",
    "$$\n",
    "Non quasistatic decoupling \n",
    "$$\n",
    "\\Delta W = \\Delta F + T\\Delta S_i\\\\\n",
    "= \\Delta E - T\\Delta S + T\\Delta S_i \\\\\n",
    "= \\Delta U - T\\Delta S + T\\Delta S_i\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we reasoned that the energy cost of a measurement is zero on average for the two cases of quasistatic coupling and decoupling and when we abruptly couple and decouple the demon from syste, but for the latter it is only true if the demon is in a non equilibrium state and is hovering right above the global potential minima. Then we would be able to recover all the lost energy from immediate decoupling, but this is not the case when demon is initially in equilibrium and the microstate probability that describes the demon's state is the boltzman's distribution in which case the demon's position likelyhood would be evenly distributed over all the possible angle orrientations. If this was so than the average potential difference gained through coupling would be much smaller than the potential difference during dceoupling because the demon would never drop to the bottom immediately. This is the reason why we were recovering more energy during coupling for shorter coupling periods, we were in fact using the knowledge of the demon's non equilibrium state in addition to the measurement of system's angle. Alright, so the best way of operating this engine appears to be immediately decouple, immediately extract energy upon measurement and again immeadiately couple the system with demon, since all these 3 processes happend almost instantaneously the cost of decoupling is balanced by the energy gained through coupling and in addition to that we are also extracting energy out of the system upon the measurement. Well actualy, if we extract the energy out of the system by shifting the potential than that will change the minimum energy state for the system demon and which will has an effect of not droping the demon straight to its previous potential state but maybe slightly higher and the energy recovered from that might exactly compensate for the energy extracted through measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_test = langevin_numba(init, t_points4, cpl_period = 1/5, dcpl_period = 1/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418d34dd7f924dbab96b7bd55f70e902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_correlation(sol_test,t_points4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quasistatic decoupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def E_cost_quas_dcpl(n, t_points, pdf = 'previous', decouple_periods = cpl_periods):\n",
    "    '''Counterpart to E_cost_quasi_cpl() function but considers different decoupling times and the coupling period is fixed to 1/5 of tf'''\n",
    "    E_cost_avg = np.empty(decouple_periods.size) \n",
    "    w_cpl_avg = np.empty(decouple_periods.size) \n",
    "    w_dcpl_avg = np.empty(decouple_periods.size) \n",
    "    \n",
    "    for i in prange(decouple_periods.size):\n",
    "        w_cpl, w_dcpl, E_costs =  E_cost(n, t_points, cpl_period = 1/5, dcpl_period = decouple_periods[i], pdf = pdf) \n",
    "        E_cost_avg[i] = np.mean(E_costs)\n",
    "        w_cpl_avg[i] = np.mean(w_cpl)\n",
    "        w_dcpl_avg[i] = np.mean(w_dcpl)\n",
    "        \n",
    "    return w_cpl_avg, w_dcpl_avg, E_cost_avg\n",
    "dcpl_t = np.arange(0.01, 3/5,0.02)\n",
    "E_dcpl_quasi = E_cost_quas_dcpl(100, t_points4, pdf = 'previous', decouple_periods = dcpl_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7ad4397d3b4aea8fed7acd47e57cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(21,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(dcpl_t, E_dcpl_quasi[-2], 'or')\n",
    "plt.title('⟨W⟩ decouple', fontsize= 20)\n",
    "plt.ylabel('E (kT)', fontsize= 15)\n",
    "plt.xlabel('$(t_f-t_d)/t_f$', fontsize= 15)\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(dcpl_t, E_dcpl_quasi[-3], 'og')\n",
    "plt.title('⟨W⟩ couple', fontsize= 20)\n",
    "plt.xlabel('$(t_f-t_d)/t_f$', fontsize= 15)\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(dcpl_t, E_dcpl_quasi[-1] ,'o', c='darkorange')\n",
    "plt.xlabel('$(t_f-t_d)/t_f$', fontsize= 15)\n",
    "plt.ylabel('$ ⟨W_{cost}⟩$ (kT)', fontsize= 15)\n",
    "plt.title('Non-equilibrium demon', fontsize= 20)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746ff903371d437187f598bce8be8a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(dcpl_t, E_dcpl_quasi[-1] ,'o', c='darkorange')\n",
    "plt.xlabel('$(t_f-t_d)/t_f$')\n",
    "plt.ylabel('$ ⟨W_{cost}⟩$ (kT)')\n",
    "plt.title('Non-equilibrium demon, Energy cost of a measurement')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qusistatic coupling and decoupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel = True) \n",
    "def E_cost_cdpl(n, t_points, pdf = 'previous'):\n",
    "    '''E cost when both the coupling and decoupling are changed simultaneously'''\n",
    "    E_cost_quas_cd = np.empty(cpl_periods.size)\n",
    "\n",
    "    for i in prange(cpl_periods.size):\n",
    "        E_cost_quas_cd[i] = np.mean( E_cost(n, t_points, cpl_period = cpl_periods[i], dcpl_period = cpl_periods[i], pdf = pdf)[-1] )\n",
    "    return E_cost_quas_cd\n",
    "\n",
    "E_cost_cdpl_previous = E_cost_cdpl(100, t_points4, pdf = 'previous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d680dda34b0f44acaae7242c69de8297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(cpl_periods, E_cost_cdpl_previous/E_unit, 'x')\n",
    "plt.xlabel('coupling|decoupling period')\n",
    "plt.ylabel('average energy cost')\n",
    "plt.title('Quasistatic coupling and decoupling')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do not know how should i feel about this, that for smaller dt (10^(-11)s) the average energy cost of a measurement is much smaller than for bigger dt (10^(-10)), we kept the time intrval over which the equations of motion were solved the same, only thing that changed was number of steps which increased by a factor of 10 and dt decrease by a factor of 10 so the numerical accuracy of solving the equations and the energy cost of measurement went up. \n",
    "\n",
    "Hm what we get above seems almost alright, for longer time periods the energy cost of measurement is finally coming down but it drops below zero and the graphs suggests that it would continue on decreasing if we made the periods even longer, not sure about this. If it is just a coincidence that the datapoints in the graph just so happen to be negative with a negative slope. I am not quite getting what is it that made the trend shift from decreasing to decreasing energy cost of measurement in comparison to the instant decouple scenario. One thing it tells us is that decoupling continuously is less energeticaly expansive than an instantaneous shift in potential energy. That is just something that I do not understand and probably has to do with the entropy and free energy concepts that I am not fully familiar with. Okay I accidently plotted on more graph below with the same dt steps and it still gives us energies that are below 0 for high coupling periods, why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0001 0.0006 0.0011 0.0016 0.0021 0.0026 0.0031 0.0036 0.0041 0.0046\n",
      " 0.0051 0.0056 0.0061 0.0066 0.0071 0.0076 0.0081 0.0086 0.0091 0.0096\n",
      " 0.0101 0.0106 0.0111 0.0116 0.0121 0.0126 0.0131 0.0136 0.0141 0.0146\n",
      " 0.0151 0.0156 0.0161 0.0166 0.0171 0.0176 0.0181 0.0186 0.0191 0.0196\n",
      " 0.0201 0.0206 0.0211 0.0216 0.0221 0.0226 0.0231 0.0236 0.0241 0.0246]\n"
     ]
    }
   ],
   "source": [
    "cpl_periods_cd = np.arange(0.0001, 0.025, 0.0005)\n",
    "E_cost_quast_cd1 = np.empty(cpl_periods_cd.size)\n",
    "print(cpl_periods_cd)\n",
    "\n",
    "#for i in range(cpl_periods_cd.size):\n",
    "#    E_cost_quast_cd1[i] = np.average( E_cost(100, t_points4, cpl_period = cpl_periods_cd[i], dcpl_period = cpl_periods_cd[i]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc867793bf904dac9f6bcb29a7d7dc98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(cpl_periods_cd, E_cost_quast_cd1/E_unit, 'x')\n",
    "plt.xlabel('coupling|decoupling period')\n",
    "plt.ylabel('average energy cost')\n",
    "plt.title('Quasistatic coupling and decoupling')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy cost of an exponential coupling\n",
    "Testing how the energy cost of measurement changes when we use exponential coupling instead of linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_many_exp = E_cost(1000, t_points4, cpl_period = 1, coupling = 'exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe1536e8c31409fa7c2fc57e745ef38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.9164946217253467\n",
      "std : 1.4092002633027014\n"
     ]
    }
   ],
   "source": [
    "plot_E_cost(w_many_exp[-1])\n",
    "\n",
    "print('mean:', np.average(w_many_exp[-1]))\n",
    "print('std :', np.std(w_many_exp[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the coupling period was set to 1 which means that at 1/5 of the total time the coupling is about 86% and at time 1/10 is about 64% which is pretty close to what it would be if we linearly coupled the demon with system (100% and 50% respectively). The energy cost for exponential coupling appears to be smaller, mean of 1.3 whereas in the linear case the mean was about 1.6 but it is hard to make a direct comparison between these two methods of coupling. I might get back to cosidering different methods of coupling later when it might make a difference in some of these statistical quantities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialized equilibrium pdf of system and demon before coupling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_many_eq = E_cost(1000, t_points4, cpl_period = 1/5, pdf = 'eq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7ebfc2b0504d7baab6a1fd6ea42a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1470.8305682877372\n",
      "1354.5818279725047\n"
     ]
    }
   ],
   "source": [
    "plot_E_cost(w_many_eq[-1])\n",
    "print(np.average(w_many_eq[-1]))\n",
    "print(np.std(w_many_eq[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_many_eq2 = E_cost(1000, t_points4, cpl_period = 1/20, pdf = 'eq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984ad8aea72440dfa48a42ac9812741c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_E_cost(w_many_eq2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quasistatic coupling and immediate decoupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_cost_quasi_eq = E_cost_quas_couple(1000, t_points_1, pdf = 'eq', couple_periods =  cpl_periods_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0da35732fb74bdea773ba52dc608633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(cpl_periods_long, E_cost_quasi_eq[-1], 'o', c='darkorange')\n",
    "plt.xlabel('$t_c/t_f$')\n",
    "plt.ylabel('$ ⟨W_{cost}⟩$ (kT)')\n",
    "plt.title('thermalized demon')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quasistatic coupling and decoupling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_cost_cdpl_eq = E_cost_cdpl(1000, t_points_1, pdf = 'eq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4688b60f17e48418ef419d00b3072f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(cpl_periods, E_cost_cdpl_eq/E_unit, 'x')\n",
    "plt.xlabel('coupling|decoupling period')\n",
    "plt.ylabel('average energy cost')\n",
    "plt.title('Quasistatic coupling and decoupling')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E gained per cycle \n",
    "This section contains a rewritten code from the above section and does almost the same thing, calculates the energy cost of a measurement, energy extracted through exploitation and the total energy gained per one operational cycle.\n",
    "\n",
    "Defining a langevin_wait that evolves the magnet's angles after they get decoupled but the system is still in contact with the coil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def langevin_wait(r,  t_points):\n",
    "    ''' Calculates the right hand sight of diff eqs\n",
    "    r is a vector containing r = [[theta_s, w_s],\n",
    "                                  [theta_d, w_d]]\n",
    "    cpl_period : the fraction of time it takes to couple the demon to the system, originaly 1/5, default is the original\n",
    "    '''\n",
    "    # initializing empty arrays that will store the resulting trajectories\n",
    "    theta_s = np.empty(t_points.shape)\n",
    "    theta_d = np.empty(t_points.shape)\n",
    "    w_s = np.empty(t_points.shape)\n",
    "    w_d = np.empty(t_points.shape)\n",
    "    \n",
    "    # t final\n",
    "    t_f = t_points[-1]\n",
    "    h = t_f/(len(t_points)-1)\n",
    "    # storing the initial values\n",
    "    theta_s[0] = r[0,0]\n",
    "    theta_d[0] = r[1,0]\n",
    "    w_s[0] = r[0,1]\n",
    "    w_d[0] = r[1,1]\n",
    "\n",
    "    # solving the dif-eq\n",
    "    for idx in range(1,len(t_points)):\n",
    "        t = t_points[idx]\n",
    "        # abreviation for variables at t\n",
    "        th_s_t =  theta_s[idx-1]\n",
    "        th_d_t = theta_d[idx-1]\n",
    "        w_s_t = w_s[idx-1]\n",
    "        w_d_t = w_d[idx-1]\n",
    "        # calculate the variables at t+dt\n",
    "        theta_s[idx] = th_s_t + h*w_s_t\n",
    "        theta_d[idx] = th_d_t + h*w_d_t\n",
    "        w_s[idx] = (w_s_t - h*S2*np.sin(th_s_t) -\n",
    "                            h*S3*w_s_t +\n",
    "                            h**(1/2)*S4*np.random.normal()  \n",
    "                    )\n",
    "        w_d[idx] = (w_d_t - h*D2*w_d_t  +\n",
    "                            h**(1/2)*D3*np.random.normal()  \n",
    "                   )\n",
    "        \n",
    "    sol = np.empty((2,2, t_points.shape[0]))\n",
    "    sol[0,0] = theta_s\n",
    "    sol[0,1] = w_s\n",
    "    sol[1,0] = theta_d\n",
    "    sol[1,1] = w_d\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit()\n",
    "def E_per_cycle(n, t_points, cpl_period = 1/5, dcpl_period = 0, extraction = 'normal', wait = 0, pdf = 'previous', coupling = 'linear'):\n",
    "    '''\n",
    "    '''\n",
    "    E_costs = np.empty(n)    # Energy cost of making the measurement\n",
    "    E_exploit = np.empty(n) # Energy extracted out of the system\n",
    "    \n",
    "    w_couples = np.empty(n)\n",
    "    w_decouples = np.empty(n)\n",
    "    \n",
    "    # constants\n",
    "    A = mu_d_max*mu_s*u_0/(4*np.pi*d**3)\n",
    "    C = B_0*mu_s\n",
    "    t_f = t_points[-1]\n",
    "    N = int(t_points.size - 1)\n",
    "    \n",
    "    # initial condition\n",
    "    init_r = init\n",
    "    \n",
    "    for run in range(n):\n",
    "        solution = langevin_numba(init_r, t_points, cpl_period = cpl_period, dcpl_period = dcpl_period, coupling = coupling)\n",
    "        # demon's and system's final angles\n",
    "        th_d_f = solution[1,0][-1] # final theta of demon\n",
    "        th_s_f = solution[0,0][-1]\n",
    "        \n",
    "        # energy it takes to couple the system and demon\n",
    "        E_couple   = work_couple_numba(solution, t_points, cpl_period = cpl_period, coupling = coupling) # energy it takes to couple \n",
    "        E_decouple = work_decouple(solution, t_points, dcpl_period = dcpl_period, coupling = coupling)   # energy it takes to decouple\n",
    "        E_costs[run] = E_couple + E_decouple                          # energy cost of the measurement  \n",
    "        \n",
    "        w_couples[run] = E_couple\n",
    "        w_decouples[run] = E_decouple\n",
    "        # Energy extraction right after decoupling\n",
    "        if (extraction == 'normal'): \n",
    "            # estimated/measuerd th_s by demon's angle\n",
    "            th_s_meas = np.arctan(2*np.sin(th_d_f)*A / (C-A*np.cos(th_d_f)))\n",
    "            # energy that goes out of the system\n",
    "            E_exploit[run] = U_system(th_s_meas - th_s_f) - U_system(th_s_f)              \n",
    "            \n",
    "        # ideal extraction in a case of a perfect measurement     \n",
    "        elif (extraction == 'perfect'):    \n",
    "            E_exploit[run] = U_0_min - U_system(th_s_f) \n",
    "        \n",
    "        # wait after the decouple.\n",
    "        elif (extraction == 'wait'):\n",
    "            N_wait = int(N*wait) # number of steps executed after decoupling\n",
    "            t_wait = np.arange(0, t_f*wait + t_f*wait/N_wait, t_f*wait/N_wait) # time during the wait period\n",
    "\n",
    "            sol_wait = langevin_wait(solution[:,:,-1], t_wait) # evolving the magnet's angles after they are decoupled\n",
    "            \n",
    "            th_s_f, th_d_f = sol_wait[0,0][-1], sol_wait[1,0][-1] # actual, system and demon's final angles\n",
    "            th_s_meas = np.arctan(2*np.sin(th_d_f)*A / (C-A*np.cos(th_d_f))) # system's angle as measured by the demon\n",
    "            E_exploit[run] = U_system(th_s_meas - th_s_f) - U_system(th_s_f) \n",
    "            \n",
    "        #Specifying the initial angles and velcoities for the next run\n",
    "        # using the angles and velocites from previous run (instantaneous decoupling and extraction of energy)\n",
    "        if (pdf == 'previous'):\n",
    "            init_r = solution[:,:,-1]\n",
    "        # angles randomized according to boltzman equilibrium distribution and the velocities set to zero, np.random.choice not recognized by numba\n",
    "        elif (pdf == 'eq'):\n",
    "            init_r = np.zeros((2,2))\n",
    "            th_d = np.random.random()*np.pi*2 - np.pi\n",
    "            th_s = np.random.normal()*pdf_s_std\n",
    "            init_r[0,0], init_r[1,0] = th_s, th_d\n",
    "            \n",
    "        # all zeros, zero velocities and angles at their respective minima\n",
    "        elif (pdf == 'zero'):\n",
    "            init_r = np.zeros((2,2))\n",
    "            init_r[1,0] = np.pi\n",
    "            \n",
    "    return E_costs, E_exploit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantaneous decoupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9704883664651413 -0.727985857764659\n"
     ]
    }
   ],
   "source": [
    "E_costs, E_exploit = E_per_cycle(1000, t_points_1, cpl_period = 1/5, extraction = 'normal')\n",
    "E_gain_n = E_exploit + E_costs\n",
    "print(np.average(E_costs)/E_unit, np.average(E_exploit)/E_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c521d7e347464ead60330cd4d5bf55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy gained per 1 operational cycle\n",
      "mean: 0.24250250870048232 \n",
      "std  : 1.1427074685845977\n"
     ]
    }
   ],
   "source": [
    "def plot_E_total(E_total):\n",
    "    plt.figure()\n",
    "\n",
    "    n, bins, patches = plt.hist(E_total/E_unit, 30)\n",
    "    plt.xlabel('E_total')\n",
    "    plt.ylabel('counts')\n",
    "    plt.title('total energy on each cycle')\n",
    "plot_E_total(E_gain_n)\n",
    "print('Energy gained per 1 operational cycle\\nmean:',np.mean(E_gain_n)/E_unit,'\\nstd  :',np.std(E_gain_n)/E_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_costs1, E_exploit1 = E_per_cycle(1000, t_points_1, cpl_period = 1/5, extraction = 'perfect')\n",
    "E_gain_n1 = E_exploit1 + E_costs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1fe163aa584a2687a2dcdbf236aa82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy gained per 1 operational cycle\n",
      "mean: -0.1911830986233045 \n",
      "std  : 1.391360636370925\n",
      "E_exploit: -1.232121705165181\n"
     ]
    }
   ],
   "source": [
    "plot_E_total(E_gain_n1)\n",
    "print('Energy gained per 1 operational cycle\\nmean:',np.mean(E_gain_n1)/E_unit,'\\nstd  :',np.std(E_gain_n1)/E_unit)\n",
    "print('E_exploit:',np.average(E_exploit1)/E_unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy extracted through measurement exploitation\n",
    "First the average energy of a perfect measurement is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_costs_expl_p, E_exploit_expl_p = E_per_cycle(100, t_points4, cpl_period = 1/5, extraction = 'perfect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.1094798258274012\n"
     ]
    }
   ],
   "source": [
    "E_expl_perfect = np.average(E_exploit_expl_p)/E_unit\n",
    "print(E_expl_perfect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_costs_expl, E_exploit_expl = E_per_cycle(100, t_points4, cpl_period = 1/5, extraction = 'normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average energy extracted <E_ext>=-0.827 +/- 0.171\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c672ce9caa594b58ae872836f59de0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Energy extracted upon measurement')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_avg_expl = np.average(E_exploit_expl)/E_unit\n",
    "E_errmean_expl = np.std(E_exploit_expl)/E_unit/np.sqrt(E_exploit_expl.size)\n",
    "print('The average energy extracted <E_ext>={0:.3f} +/- {1:.3f}'.format(E_avg_expl,E_errmean_expl))\n",
    "plt.figure()\n",
    "\n",
    "plt.hist(E_exploit_expl/E_unit, 80, color='g')\n",
    "plt.xlabel('$<E_{extract}>$ (kT)')\n",
    "plt.ylabel('counts')\n",
    "plt.xlim([-5,3])\n",
    "plt.axvline(x= E_avg_expl, ymin=0, c='orange', linestyle=\"--\")\n",
    "plt.text(-1.05,17000, 'average  {:0.2f}'.format(E_avg_expl), rotation=90)\n",
    "plt.title('Energy extracted upon measurement')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous decoupling \n",
    "Nice results, nice, I tested how the energy change changes as the decouple period is made shorter. We started of 1/5 and that was too long, so long that there was no coupling correlation between the magnets left at the end of the process and the energy exploit on average was positive (energy lost during exploitation process). As the decoupling period was made shoter and we effectively decoupled faster the energy exploited and thus energy changed was getting smaller and smaller until it breached negative numbers. The point of the story is that we have to decouple fairly quickly if we want to maintain some coupling between the system and demon that could be exploited to extract positive energy out of the system. What is pleasing to see is that there is a trade-off between energy exploited and energy cost of measurement depending on the length of the decoupling period. The longer the period, the longer we wait and the less effective the demon's measurement is, but because we wait longer we waste less energy during the decoupling process. In reverse, it is desirable to immediately decouple the demon from the system because it would give us the most accurate measurement of system's angle and the energy exploit would be high, but a sudden decoupling is a non-quisistatic process which is very wastefull and the energy cost of measurement is bigger than for slower finite decoupling. This can be nicely visualised with a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9752533594286605 -0.7433269614085294\n"
     ]
    }
   ],
   "source": [
    "E_costs2, E_exploit2 = E_per_cycle(1000, t_points_1, cpl_period = 1/5, dcpl_period = 1/1000, extraction = 'normal')\n",
    "E_gain_n2 = E_exploit2 + E_costs2\n",
    "print(np.average(E_costs2)/E_unit, np.average(E_exploit2)/E_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f03f52b777441719d5df728e5e43576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy gained per 1 operational cycle\n",
      "mean: 0.23192639802013107 \n",
      "std  : 1.1448777593459478\n"
     ]
    }
   ],
   "source": [
    "plot_E_total(E_gain_n2)\n",
    "print('Energy gained per 1 operational cycle\\nmean:',np.mean(E_gain_n2)/E_unit,'\\nstd  :',np.std(E_gain_n2)/E_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8737471899251422 1.76401044486292\n"
     ]
    }
   ],
   "source": [
    "E_costs3, E_exploit3 = E_per_cycle(1000, t_points_1, cpl_period = 1/5, dcpl_period = 2/5, extraction = 'normal')\n",
    "E_gain_n3 = E_exploit3 + E_costs3\n",
    "print(np.mean(E_costs3)/E_unit, np.average(E_exploit3)/E_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5ed4e29f1e4722ab30bc56cf96736f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy gained per 1 operational cycle\n",
      "mean: 2.6377576347880622 \n",
      "std  : 3.248405809283578\n"
     ]
    }
   ],
   "source": [
    "plot_E_total(E_gain_n3)\n",
    "print('Energy gained per 1 operational cycle\\nmean:',np.mean(E_gain_n3)/E_unit,'\\nstd  :',np.std(E_gain_n3)/E_unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLOW-IMMEDIATE decoupling trade off\n",
    "Visualizing how the energy change, energy exploit and energy cost changes for different decoupling periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcpl_periods = np.arange(0.01,0.2, 0.01)\n",
    "\n",
    "@njit(parallel=True)\n",
    "def quasi_dcpl_trade(n, pdf = 'previos'):\n",
    "    E_cost_trade = np.empty(dcpl_periods.size)\n",
    "    E_exploit_trade = np.empty(dcpl_periods.size)\n",
    "    E_change_trade = np.empty(dcpl_periods.size)\n",
    "    \n",
    "    for dcpl in prange(dcpl_periods.size):\n",
    "        E_cost_t, E_exploit_t = E_per_cycle(n, t_points_1, cpl_period = 1/5, dcpl_period = dcpl_periods[dcpl], pdf = pdf, extraction = 'normal')\n",
    "        E_cost_trade[dcpl] = np.mean(E_cost_t)\n",
    "        E_exploit_trade[dcpl] = np.mean(E_exploit_t)\n",
    "        E_change_trade[dcpl] = E_cost_trade[dcpl] + E_exploit_trade[dcpl]\n",
    "        \n",
    "    return E_cost_trade/E_unit, E_exploit_trade/E_unit, E_change_trade/E_unit\n",
    "\n",
    "#E_c_trade, E_exp_trade, E_change_trade = quasi_dcpl_trade(1000, pdf='previous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9374737ee4024c4a83decc8279b05457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'E_exp_trade' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-94dd0195f627>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdcpl_periods\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mE_exp_trade\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'E extract'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdcpl_periods\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mE_change_trade\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'E total'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdcpl_periods\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mE_c_trade\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'E cost'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'E_exp_trade' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(dcpl_periods, E_exp_trade ,label='E extract')\n",
    "plt.plot(dcpl_periods, E_change_trade ,label='E total')\n",
    "plt.plot(dcpl_periods, E_c_trade, label='E cost')\n",
    "plt.xlabel('$(t_f-t_d)/t_f$')\n",
    "plt.ylabel('E (kT)')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title('Slow-immediate decoupling trade off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aaaah beatiful, the exploitation energy start of by being useful and as the decoupling period is made longer the energy exploit flips to costing us energy instead of pumping energy out of the system. In contrast, the energy cost of measurement starts of high, being expensive becasue we non-quisistaticly decouple the magnets and for slower decoupling that cost goes down. Nevertheless the energy change which is the total energy gained/lost per engine's 1 operational cycle steadily  keeps increasing. If the dceoupling period was made even shorter we would get closer to zero net energy. In the case of a perfect measurement the net energy would cross the zero line into negative numbers and we would see a succesful operation of an engine. What might be of interest next is the increase of maximum coupling between the magnets, which should improve the performance of the engine and hopefuly give negative change in energies per cycle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy gained of a delayed measurement\n",
    "In this section we will explore the changes in energy gained through measurement exploitation and total energy gained from the engine's operation per cycle as we delay the measurement of the system's angle after the magnets become completely decoupled. This means that we will wait some time after the magnets are fully decoupled and then we take the measurement of the system's angle and extract its energy out by shifting the coil's orientation. On average we would expect lower energy gains from exploitation for longer waiting periods.\n",
    "\n",
    "We would like to probe how the energy cost of coupling changes as we slow down the turning on of the magnet's magnetic moment making it closer to a quasistatic process. It is expected to see a decrease in the cost because less heat should be transfered during the process, that is what the theory it is not something that I personaly understand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_times =  np.linspace(10**(-3), 0.03, 10) # fraction of 1 cycle time we wait after decoupling\n",
    "E_costs_many = np.empty(wait_times.shape)                    # Energy costs of measurement\n",
    "E_exploit_many = np.empty(wait_times.shape)\n",
    "\n",
    "for run in range(wait_times.size):\n",
    "    E_costs, E_exploit = E_per_cycle(1000, t_points_1, cpl_period = 1/5, extraction = 'wait', wait = wait_times[run]) \n",
    "    E_costs_many[run] = np.average(E_costs)/E_unit\n",
    "    E_exploit_many[run] = np.average(E_exploit)/E_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_gained_many = E_costs_many + E_exploit_many\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(wait_times, E_exploit_many, label = '<E exploit>')\n",
    "plt.plot(wait_times, E_gained_many, label = '<E gained>')\n",
    "plt.plot(wait_times, E_costs_many, label = '<E meas. cost>')\n",
    "plt.xlabel(\"waited time fraction\")\n",
    "plt.ylabel('E (kT)')\n",
    "plt.title('Energy transfers after a delayed measurement')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure shows how the energy acquired through exploitation period and the total gained energy per cycle changes as we delay time of a measurement after the magnets are decoupled. First thing to notice is that the energy cost of a measurement stays unchanged as it is unaffected by delaying of the measurement. The blue line which represents the average energy extracted from the system upon measuring approaches zero and then it surpasses to positive numbers with a steady slope. After the time it crosses 0 the demon's measurement is no more useful to us. What is not obvious at first is the ever increasing energy extracted upon the measurement, so not only that we do not extract positive energy out of the system but we waste the energy by trying to aling the coil with the system magnet. In the case of magnets in harmonic potential, their movement was restricted to oscillations around the equilibrium points so I would guess that the after the oscillators became completely independent of each other, the measurement would be a completely random guess of the system's position and the energy extracted on average would be zero or, negative (meaning that we waste enregy by trying to gain energy, opposite of the sign convention above). But here with the magnets we see that as we wait longer the energy we waste by acting upon the demon's measurement is getting more and more positive (we loos energy instead of gain energy). This is because once the magnets stop interacting, the demon's motion becomes unconstrained and it goes on to wander over its entire range of allowed angles, from -pi to pi, whereas the system's motion is still modulated by the the coil's magnetic field, confining it to move around its equilibrium point and not deviate much from that. Since we were using the minimum of the interaction potential energy to measure the system's angle, the measurement would approximately tell us that the system is on the other side of the demon, but it really isnt because the demon when far out while the system stayed where it was before. Therefore this energy loss from exploitation period will be getting bigger and bigger because the demon will go futher and futhre away from the system's bottom of the potential well. If we ran the simulations for long enough (long wait time) we would eventually hit a constant average energy lost per cycle upon the measurement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
